{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util import get_data_from_kaggle,sentiment_analysis , aggregate_tweet, restructure_date_information, get_static_df, one_label_scale_static_df, scale_stock_data\n",
    "from constant import Constant\n",
    "import pandas as pd\n",
    "from TFT import TFT_embedding, TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFT.tft.TFT"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<constant.Constant at 0x290ffeffb10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant = Constant()\n",
    "constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock, tweet = get_data_from_kaggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = pd.read_csv('processed.csv')\n",
    "#tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Positive_Avg</th>\n",
       "      <th>Neutral_Avg</th>\n",
       "      <th>Negative_Avg</th>\n",
       "      <th>Positive_Count</th>\n",
       "      <th>Neutral_Count</th>\n",
       "      <th>Negative_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>0.322527</td>\n",
       "      <td>0.465190</td>\n",
       "      <td>0.212283</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>0.063409</td>\n",
       "      <td>0.574801</td>\n",
       "      <td>0.361790</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021-10-02</td>\n",
       "      <td>0.053914</td>\n",
       "      <td>0.569441</td>\n",
       "      <td>0.376645</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>0.365725</td>\n",
       "      <td>0.546062</td>\n",
       "      <td>0.088213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>0.082445</td>\n",
       "      <td>0.740438</td>\n",
       "      <td>0.177116</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>ZS</td>\n",
       "      <td>2022-09-18</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.195517</td>\n",
       "      <td>0.802136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>ZS</td>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>0.025520</td>\n",
       "      <td>0.272998</td>\n",
       "      <td>0.701482</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>ZS</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>0.060069</td>\n",
       "      <td>0.497830</td>\n",
       "      <td>0.442101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>ZS</td>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>0.129386</td>\n",
       "      <td>0.716569</td>\n",
       "      <td>0.154045</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>ZS</td>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.264248</td>\n",
       "      <td>0.731651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5910 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Stock Name        Date  Positive_Avg  Neutral_Avg  Negative_Avg  \\\n",
       "0          AAPL  2021-09-30      0.322527     0.465190      0.212283   \n",
       "1          AAPL  2021-10-01      0.063409     0.574801      0.361790   \n",
       "2          AAPL  2021-10-02      0.053914     0.569441      0.376645   \n",
       "3          AAPL  2021-10-03      0.365725     0.546062      0.088213   \n",
       "4          AAPL  2021-10-04      0.082445     0.740438      0.177116   \n",
       "...         ...         ...           ...          ...           ...   \n",
       "5905         ZS  2022-09-18      0.002347     0.195517      0.802136   \n",
       "5906         ZS  2022-09-21      0.025520     0.272998      0.701482   \n",
       "5907         ZS  2022-09-27      0.060069     0.497830      0.442101   \n",
       "5908         ZS  2022-09-28      0.129386     0.716569      0.154045   \n",
       "5909         ZS  2022-09-29      0.004101     0.264248      0.731651   \n",
       "\n",
       "      Positive_Count  Neutral_Count  Negative_Count  \n",
       "0                  3              4               0  \n",
       "1                  0              8               3  \n",
       "2                  0              2               2  \n",
       "3                  0              1               0  \n",
       "4                  0             10               0  \n",
       "...              ...            ...             ...  \n",
       "5905               0              0               1  \n",
       "5906               0              0               1  \n",
       "5907               0              1               0  \n",
       "5908               0              1               0  \n",
       "5909               0              0               1  \n",
       "\n",
       "[5910 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_tweet = aggregate_tweet(tweet)\n",
    "aggregated_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock['Date'] = pd.to_datetime(stock['Date'] ).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(aggregated_tweet, stock, on=['Date', 'Stock Name'], how='right')\n",
    "merged_df = merged_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = restructure_date_information(merged_df)\n",
    "#processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luan\\Documents\\DL\\TFT\\data_util.py:74: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  static_df.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "static = get_static_df(processed_df,  constant.static_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Consumer Cyclical', 'United States', 2.295], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static[[\"sector\", \"country\", \"beta\"]].loc[\"TSLA\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = one_label_scale_static_df(static,constant.static_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import TFT_Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "x = TFT_Dataset(stock_df= processed_df , \n",
    "                static_df=static_df,\n",
    "                constant_variable=constant, \n",
    "                history_length= 5, \n",
    "                prediction_length= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(x, batch_size= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3658, 1.0000, 0.2182, 0.1214, 0.0701, 0.1094, 0.5818],\n",
       "         [0.3658, 1.0000, 0.2182, 0.1214, 0.0701, 0.1094, 0.5818],\n",
       "         [0.3658, 1.0000, 0.2182, 0.1214, 0.0701, 0.1094, 0.5818],\n",
       "         [0.3658, 1.0000, 0.2182, 0.1214, 0.0701, 0.1094, 0.5818],\n",
       "         [0.3658, 1.0000, 0.2182, 0.1214, 0.0701, 0.1094, 0.5818],\n",
       "         [0.3658, 1.0000, 0.2182, 0.1214, 0.0701, 0.1094, 0.5818],\n",
       "         [0.3658, 1.0000, 0.2182, 0.1214, 0.0701, 0.1094, 0.5818],\n",
       "         [0.3658, 1.0000, 0.2182, 0.1214, 0.0701, 0.1094, 0.5818],\n",
       "         [0.3658, 1.0000, 0.2182, 0.1214, 0.0701, 0.1094, 0.5818],\n",
       "         [0.3658, 1.0000, 0.2182, 0.1214, 0.0701, 0.1094, 0.5818]]),\n",
       " tensor([[4, 5, 2],\n",
       "         [4, 5, 2],\n",
       "         [4, 5, 2],\n",
       "         [4, 5, 2],\n",
       "         [4, 5, 2],\n",
       "         [4, 5, 2],\n",
       "         [4, 5, 2],\n",
       "         [4, 5, 2],\n",
       "         [4, 5, 2],\n",
       "         [4, 5, 2]], dtype=torch.int32),\n",
       " tensor([[[3.2253e-01, 4.6519e-01, 2.1228e-01, 3.0000e+00, 4.0000e+00,\n",
       "           0.0000e+00, 1.4366e+02, 1.4438e+02, 1.4128e+02, 1.4048e+02,\n",
       "           8.9057e+07],\n",
       "          [6.3409e-02, 5.7480e-01, 3.6179e-01, 0.0000e+00, 8.0000e+00,\n",
       "           3.0000e+00, 1.4190e+02, 1.4292e+02, 1.3911e+02, 1.4162e+02,\n",
       "           9.4640e+07],\n",
       "          [8.2445e-02, 7.4044e-01, 1.7712e-01, 0.0000e+00, 1.0000e+01,\n",
       "           0.0000e+00, 1.4176e+02, 1.4221e+02, 1.3827e+02, 1.3814e+02,\n",
       "           9.8322e+07],\n",
       "          [1.2075e-01, 7.9165e-01, 8.7594e-02, 0.0000e+00, 5.0000e+00,\n",
       "           0.0000e+00, 1.3949e+02, 1.4224e+02, 1.3936e+02, 1.4009e+02,\n",
       "           8.0861e+07],\n",
       "          [8.1693e-02, 5.7970e-01, 3.3861e-01, 0.0000e+00, 7.0000e+00,\n",
       "           3.0000e+00, 1.3947e+02, 1.4215e+02, 1.3837e+02, 1.4097e+02,\n",
       "           8.3221e+07]],\n",
       " \n",
       "         [[6.3409e-02, 5.7480e-01, 3.6179e-01, 0.0000e+00, 8.0000e+00,\n",
       "           3.0000e+00, 1.4190e+02, 1.4292e+02, 1.3911e+02, 1.4162e+02,\n",
       "           9.4640e+07],\n",
       "          [8.2445e-02, 7.4044e-01, 1.7712e-01, 0.0000e+00, 1.0000e+01,\n",
       "           0.0000e+00, 1.4176e+02, 1.4221e+02, 1.3827e+02, 1.3814e+02,\n",
       "           9.8322e+07],\n",
       "          [1.2075e-01, 7.9165e-01, 8.7594e-02, 0.0000e+00, 5.0000e+00,\n",
       "           0.0000e+00, 1.3949e+02, 1.4224e+02, 1.3936e+02, 1.4009e+02,\n",
       "           8.0861e+07],\n",
       "          [8.1693e-02, 5.7970e-01, 3.3861e-01, 0.0000e+00, 7.0000e+00,\n",
       "           3.0000e+00, 1.3947e+02, 1.4215e+02, 1.3837e+02, 1.4097e+02,\n",
       "           8.3221e+07],\n",
       "          [4.5129e-02, 6.4188e-01, 3.1299e-01, 0.0000e+00, 6.0000e+00,\n",
       "           2.0000e+00, 1.4306e+02, 1.4422e+02, 1.4272e+02, 1.4226e+02,\n",
       "           6.1733e+07]],\n",
       " \n",
       "         [[8.2445e-02, 7.4044e-01, 1.7712e-01, 0.0000e+00, 1.0000e+01,\n",
       "           0.0000e+00, 1.4176e+02, 1.4221e+02, 1.3827e+02, 1.3814e+02,\n",
       "           9.8322e+07],\n",
       "          [1.2075e-01, 7.9165e-01, 8.7594e-02, 0.0000e+00, 5.0000e+00,\n",
       "           0.0000e+00, 1.3949e+02, 1.4224e+02, 1.3936e+02, 1.4009e+02,\n",
       "           8.0861e+07],\n",
       "          [8.1693e-02, 5.7970e-01, 3.3861e-01, 0.0000e+00, 7.0000e+00,\n",
       "           3.0000e+00, 1.3947e+02, 1.4215e+02, 1.3837e+02, 1.4097e+02,\n",
       "           8.3221e+07],\n",
       "          [4.5129e-02, 6.4188e-01, 3.1299e-01, 0.0000e+00, 6.0000e+00,\n",
       "           2.0000e+00, 1.4306e+02, 1.4422e+02, 1.4272e+02, 1.4226e+02,\n",
       "           6.1733e+07],\n",
       "          [1.1716e-01, 4.3652e-01, 4.4631e-01, 1.0000e+00, 3.0000e+00,\n",
       "           3.0000e+00, 1.4403e+02, 1.4418e+02, 1.4256e+02, 1.4187e+02,\n",
       "           5.8773e+07]],\n",
       " \n",
       "         [[1.2075e-01, 7.9165e-01, 8.7594e-02, 0.0000e+00, 5.0000e+00,\n",
       "           0.0000e+00, 1.3949e+02, 1.4224e+02, 1.3936e+02, 1.4009e+02,\n",
       "           8.0861e+07],\n",
       "          [8.1693e-02, 5.7970e-01, 3.3861e-01, 0.0000e+00, 7.0000e+00,\n",
       "           3.0000e+00, 1.3947e+02, 1.4215e+02, 1.3837e+02, 1.4097e+02,\n",
       "           8.3221e+07],\n",
       "          [4.5129e-02, 6.4188e-01, 3.1299e-01, 0.0000e+00, 6.0000e+00,\n",
       "           2.0000e+00, 1.4306e+02, 1.4422e+02, 1.4272e+02, 1.4226e+02,\n",
       "           6.1733e+07],\n",
       "          [1.1716e-01, 4.3652e-01, 4.4631e-01, 1.0000e+00, 3.0000e+00,\n",
       "           3.0000e+00, 1.4403e+02, 1.4418e+02, 1.4256e+02, 1.4187e+02,\n",
       "           5.8773e+07],\n",
       "          [1.8189e-01, 4.5397e-01, 3.6414e-01, 0.0000e+00, 1.0000e+00,\n",
       "           1.0000e+00, 1.4227e+02, 1.4481e+02, 1.4181e+02, 1.4178e+02,\n",
       "           6.4452e+07]],\n",
       " \n",
       "         [[8.1693e-02, 5.7970e-01, 3.3861e-01, 0.0000e+00, 7.0000e+00,\n",
       "           3.0000e+00, 1.3947e+02, 1.4215e+02, 1.3837e+02, 1.4097e+02,\n",
       "           8.3221e+07],\n",
       "          [4.5129e-02, 6.4188e-01, 3.1299e-01, 0.0000e+00, 6.0000e+00,\n",
       "           2.0000e+00, 1.4306e+02, 1.4422e+02, 1.4272e+02, 1.4226e+02,\n",
       "           6.1733e+07],\n",
       "          [1.1716e-01, 4.3652e-01, 4.4631e-01, 1.0000e+00, 3.0000e+00,\n",
       "           3.0000e+00, 1.4403e+02, 1.4418e+02, 1.4256e+02, 1.4187e+02,\n",
       "           5.8773e+07],\n",
       "          [1.8189e-01, 4.5397e-01, 3.6414e-01, 0.0000e+00, 1.0000e+00,\n",
       "           1.0000e+00, 1.4227e+02, 1.4481e+02, 1.4181e+02, 1.4178e+02,\n",
       "           6.4452e+07],\n",
       "          [1.4911e-01, 5.4776e-01, 3.0313e-01, 2.0000e+00, 1.6000e+01,\n",
       "           5.0000e+00, 1.4323e+02, 1.4325e+02, 1.4104e+02, 1.4049e+02,\n",
       "           7.3036e+07]],\n",
       " \n",
       "         [[4.5129e-02, 6.4188e-01, 3.1299e-01, 0.0000e+00, 6.0000e+00,\n",
       "           2.0000e+00, 1.4306e+02, 1.4422e+02, 1.4272e+02, 1.4226e+02,\n",
       "           6.1733e+07],\n",
       "          [1.1716e-01, 4.3652e-01, 4.4631e-01, 1.0000e+00, 3.0000e+00,\n",
       "           3.0000e+00, 1.4403e+02, 1.4418e+02, 1.4256e+02, 1.4187e+02,\n",
       "           5.8773e+07],\n",
       "          [1.8189e-01, 4.5397e-01, 3.6414e-01, 0.0000e+00, 1.0000e+00,\n",
       "           1.0000e+00, 1.4227e+02, 1.4481e+02, 1.4181e+02, 1.4178e+02,\n",
       "           6.4452e+07],\n",
       "          [1.4911e-01, 5.4776e-01, 3.0313e-01, 2.0000e+00, 1.6000e+01,\n",
       "           5.0000e+00, 1.4323e+02, 1.4325e+02, 1.4104e+02, 1.4049e+02,\n",
       "           7.3036e+07],\n",
       "          [8.2323e-02, 5.9383e-01, 3.2385e-01, 0.0000e+00, 4.0000e+00,\n",
       "           1.0000e+00, 1.4124e+02, 1.4140e+02, 1.3920e+02, 1.3989e+02,\n",
       "           7.8763e+07]],\n",
       " \n",
       "         [[1.1716e-01, 4.3652e-01, 4.4631e-01, 1.0000e+00, 3.0000e+00,\n",
       "           3.0000e+00, 1.4403e+02, 1.4418e+02, 1.4256e+02, 1.4187e+02,\n",
       "           5.8773e+07],\n",
       "          [1.8189e-01, 4.5397e-01, 3.6414e-01, 0.0000e+00, 1.0000e+00,\n",
       "           1.0000e+00, 1.4227e+02, 1.4481e+02, 1.4181e+02, 1.4178e+02,\n",
       "           6.4452e+07],\n",
       "          [1.4911e-01, 5.4776e-01, 3.0313e-01, 2.0000e+00, 1.6000e+01,\n",
       "           5.0000e+00, 1.4323e+02, 1.4325e+02, 1.4104e+02, 1.4049e+02,\n",
       "           7.3036e+07],\n",
       "          [8.2323e-02, 5.9383e-01, 3.2385e-01, 0.0000e+00, 4.0000e+00,\n",
       "           1.0000e+00, 1.4124e+02, 1.4140e+02, 1.3920e+02, 1.3989e+02,\n",
       "           7.8763e+07],\n",
       "          [1.4820e-02, 4.3594e-01, 5.4924e-01, 0.0000e+00, 7.0000e+00,\n",
       "           8.0000e+00, 1.4211e+02, 1.4388e+02, 1.4151e+02, 1.4272e+02,\n",
       "           6.9907e+07]],\n",
       " \n",
       "         [[1.8189e-01, 4.5397e-01, 3.6414e-01, 0.0000e+00, 1.0000e+00,\n",
       "           1.0000e+00, 1.4227e+02, 1.4481e+02, 1.4181e+02, 1.4178e+02,\n",
       "           6.4452e+07],\n",
       "          [1.4911e-01, 5.4776e-01, 3.0313e-01, 2.0000e+00, 1.6000e+01,\n",
       "           5.0000e+00, 1.4323e+02, 1.4325e+02, 1.4104e+02, 1.4049e+02,\n",
       "           7.3036e+07],\n",
       "          [8.2323e-02, 5.9383e-01, 3.2385e-01, 0.0000e+00, 4.0000e+00,\n",
       "           1.0000e+00, 1.4124e+02, 1.4140e+02, 1.3920e+02, 1.3989e+02,\n",
       "           7.8763e+07],\n",
       "          [1.4820e-02, 4.3594e-01, 5.4924e-01, 0.0000e+00, 7.0000e+00,\n",
       "           8.0000e+00, 1.4211e+02, 1.4388e+02, 1.4151e+02, 1.4272e+02,\n",
       "           6.9907e+07],\n",
       "          [1.0966e-01, 5.5673e-01, 3.3362e-01, 1.0000e+00, 3.0000e+00,\n",
       "           3.0000e+00, 1.4377e+02, 1.4490e+02, 1.4351e+02, 1.4379e+02,\n",
       "           6.7940e+07]],\n",
       " \n",
       "         [[1.4911e-01, 5.4776e-01, 3.0313e-01, 2.0000e+00, 1.6000e+01,\n",
       "           5.0000e+00, 1.4323e+02, 1.4325e+02, 1.4104e+02, 1.4049e+02,\n",
       "           7.3036e+07],\n",
       "          [8.2323e-02, 5.9383e-01, 3.2385e-01, 0.0000e+00, 4.0000e+00,\n",
       "           1.0000e+00, 1.4124e+02, 1.4140e+02, 1.3920e+02, 1.3989e+02,\n",
       "           7.8763e+07],\n",
       "          [1.4820e-02, 4.3594e-01, 5.4924e-01, 0.0000e+00, 7.0000e+00,\n",
       "           8.0000e+00, 1.4211e+02, 1.4388e+02, 1.4151e+02, 1.4272e+02,\n",
       "           6.9907e+07],\n",
       "          [1.0966e-01, 5.5673e-01, 3.3362e-01, 1.0000e+00, 3.0000e+00,\n",
       "           3.0000e+00, 1.4377e+02, 1.4490e+02, 1.4351e+02, 1.4379e+02,\n",
       "           6.7940e+07],\n",
       "          [9.3549e-02, 3.9295e-01, 5.1350e-01, 2.0000e+00, 1.0000e+01,\n",
       "           1.1000e+01, 1.4345e+02, 1.4684e+02, 1.4316e+02, 1.4549e+02,\n",
       "           8.5589e+07]],\n",
       " \n",
       "         [[8.2323e-02, 5.9383e-01, 3.2385e-01, 0.0000e+00, 4.0000e+00,\n",
       "           1.0000e+00, 1.4124e+02, 1.4140e+02, 1.3920e+02, 1.3989e+02,\n",
       "           7.8763e+07],\n",
       "          [1.4820e-02, 4.3594e-01, 5.4924e-01, 0.0000e+00, 7.0000e+00,\n",
       "           8.0000e+00, 1.4211e+02, 1.4388e+02, 1.4151e+02, 1.4272e+02,\n",
       "           6.9907e+07],\n",
       "          [1.0966e-01, 5.5673e-01, 3.3362e-01, 1.0000e+00, 3.0000e+00,\n",
       "           3.0000e+00, 1.4377e+02, 1.4490e+02, 1.4351e+02, 1.4379e+02,\n",
       "           6.7940e+07],\n",
       "          [9.3549e-02, 3.9295e-01, 5.1350e-01, 2.0000e+00, 1.0000e+01,\n",
       "           1.1000e+01, 1.4345e+02, 1.4684e+02, 1.4316e+02, 1.4549e+02,\n",
       "           8.5589e+07],\n",
       "          [7.6453e-02, 4.2839e-01, 4.9516e-01, 1.0000e+00, 6.0000e+00,\n",
       "           7.0000e+00, 1.4701e+02, 1.4917e+02, 1.4655e+02, 1.4769e+02,\n",
       "           7.6379e+07]]]),\n",
       " tensor([[[ 8, 29,  3, 38],\n",
       "          [ 9,  0,  4, 38],\n",
       "          [ 9,  3,  0, 39],\n",
       "          [ 9,  4,  1, 39],\n",
       "          [ 9,  5,  2, 39]],\n",
       " \n",
       "         [[ 9,  0,  4, 38],\n",
       "          [ 9,  3,  0, 39],\n",
       "          [ 9,  4,  1, 39],\n",
       "          [ 9,  5,  2, 39],\n",
       "          [ 9,  6,  3, 39]],\n",
       " \n",
       "         [[ 9,  3,  0, 39],\n",
       "          [ 9,  4,  1, 39],\n",
       "          [ 9,  5,  2, 39],\n",
       "          [ 9,  6,  3, 39],\n",
       "          [ 9,  7,  4, 39]],\n",
       " \n",
       "         [[ 9,  4,  1, 39],\n",
       "          [ 9,  5,  2, 39],\n",
       "          [ 9,  6,  3, 39],\n",
       "          [ 9,  7,  4, 39],\n",
       "          [ 9, 10,  0, 40]],\n",
       " \n",
       "         [[ 9,  5,  2, 39],\n",
       "          [ 9,  6,  3, 39],\n",
       "          [ 9,  7,  4, 39],\n",
       "          [ 9, 10,  0, 40],\n",
       "          [ 9, 11,  1, 40]],\n",
       " \n",
       "         [[ 9,  6,  3, 39],\n",
       "          [ 9,  7,  4, 39],\n",
       "          [ 9, 10,  0, 40],\n",
       "          [ 9, 11,  1, 40],\n",
       "          [ 9, 12,  2, 40]],\n",
       " \n",
       "         [[ 9,  7,  4, 39],\n",
       "          [ 9, 10,  0, 40],\n",
       "          [ 9, 11,  1, 40],\n",
       "          [ 9, 12,  2, 40],\n",
       "          [ 9, 13,  3, 40]],\n",
       " \n",
       "         [[ 9, 10,  0, 40],\n",
       "          [ 9, 11,  1, 40],\n",
       "          [ 9, 12,  2, 40],\n",
       "          [ 9, 13,  3, 40],\n",
       "          [ 9, 14,  4, 40]],\n",
       " \n",
       "         [[ 9, 11,  1, 40],\n",
       "          [ 9, 12,  2, 40],\n",
       "          [ 9, 13,  3, 40],\n",
       "          [ 9, 14,  4, 40],\n",
       "          [ 9, 17,  0, 41]],\n",
       " \n",
       "         [[ 9, 12,  2, 40],\n",
       "          [ 9, 13,  3, 40],\n",
       "          [ 9, 14,  4, 40],\n",
       "          [ 9, 17,  0, 41],\n",
       "          [ 9, 18,  1, 41]]]),\n",
       " tensor([[[ 9,  6,  3, 39],\n",
       "          [ 9,  7,  4, 39]],\n",
       " \n",
       "         [[ 9,  7,  4, 39],\n",
       "          [ 9, 10,  0, 40]],\n",
       " \n",
       "         [[ 9, 10,  0, 40],\n",
       "          [ 9, 11,  1, 40]],\n",
       " \n",
       "         [[ 9, 11,  1, 40],\n",
       "          [ 9, 12,  2, 40]],\n",
       " \n",
       "         [[ 9, 12,  2, 40],\n",
       "          [ 9, 13,  3, 40]],\n",
       " \n",
       "         [[ 9, 13,  3, 40],\n",
       "          [ 9, 14,  4, 40]],\n",
       " \n",
       "         [[ 9, 14,  4, 40],\n",
       "          [ 9, 17,  0, 41]],\n",
       " \n",
       "         [[ 9, 17,  0, 41],\n",
       "          [ 9, 18,  1, 41]],\n",
       " \n",
       "         [[ 9, 18,  1, 41],\n",
       "          [ 9, 19,  2, 41]],\n",
       " \n",
       "         [[ 9, 19,  2, 41],\n",
       "          [ 9, 20,  3, 41]]]),\n",
       " tensor([[[143.2900],\n",
       "          [142.9000]],\n",
       " \n",
       "         [[142.9000],\n",
       "          [142.8100]],\n",
       " \n",
       "         [[142.8100],\n",
       "          [141.5100]],\n",
       " \n",
       "         [[141.5100],\n",
       "          [140.9100]],\n",
       " \n",
       "         [[140.9100],\n",
       "          [143.7600]],\n",
       " \n",
       "         [[143.7600],\n",
       "          [144.8400]],\n",
       " \n",
       "         [[144.8400],\n",
       "          [146.5500]],\n",
       " \n",
       "         [[146.5500],\n",
       "          [148.7600]],\n",
       " \n",
       "         [[148.7600],\n",
       "          [149.2600]],\n",
       " \n",
       "         [[149.2600],\n",
       "          [149.4800]]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count =0\n",
    "for static_cont_input, static_cat_input,history_cont_input, history_cat_input, future_input, prediction in loader:\n",
    "    break\n",
    "static_cont_input, static_cat_input,history_cont_input, history_cat_input, future_input, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util import get_feature_length\n",
    "\n",
    "history_cat_feature_num_list, history_cont_feature_num = get_feature_length(processed_df, constant.feature_variables)\n",
    "static_cat_feature_num_list , static_cont_feature_num  = get_feature_length(static, constant.static_variables)\n",
    "future_feature_num          , _                        = get_feature_length(processed_df, constant.future_feature)\n",
    "_                           , prediction_con           = get_feature_length(processed_df, constant.prediction_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 31, 5, 52]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_cat_feature_num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_input, history_input, future_emb = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 64, 5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 64, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(future_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = history_input.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TFT import GRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_gru = [  GRN(64,64)     for i in range(feature_size)    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [ feature_gru[i](history_input[:,:,:,i]) for i in range(feature_size)    ]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4002, -0.8560,  0.5732,  1.1735],\n",
       "         [-0.1852, -0.3178,  1.0571, -0.0367],\n",
       "         [-0.2055, -0.2240, -0.8033, -0.8358],\n",
       "         ...,\n",
       "         [ 0.0421, -0.2011,  1.2316,  0.8858],\n",
       "         [ 0.2406, -1.3437,  0.1829,  0.9423],\n",
       "         [ 0.3222,  1.3329, -0.0996,  0.3477]],\n",
       "\n",
       "        [[ 0.4002, -0.8560,  0.5732,  1.1735],\n",
       "         [-0.1852, -0.3178,  1.0571, -0.0367],\n",
       "         [-0.2055, -0.2240, -0.8033, -0.8358],\n",
       "         ...,\n",
       "         [ 0.0421, -0.2011,  1.2316,  0.8858],\n",
       "         [ 0.2406, -1.3437,  0.1829,  0.9423],\n",
       "         [ 0.3222,  1.3329, -0.0996,  0.3477]],\n",
       "\n",
       "        [[ 0.4002, -0.8560,  0.5732,  1.1735],\n",
       "         [-0.1852, -0.3178,  1.0571, -0.0367],\n",
       "         [-0.2055, -0.2240, -0.8033, -0.8358],\n",
       "         ...,\n",
       "         [ 0.0421, -0.2011,  1.2316,  0.8858],\n",
       "         [ 0.2406, -1.3437,  0.1829,  0.9423],\n",
       "         [ 0.3222,  1.3329, -0.0996,  0.3477]],\n",
       "\n",
       "        [[ 0.4002, -0.8560,  0.5732,  1.1735],\n",
       "         [-0.1852, -0.3178,  1.0571, -0.0367],\n",
       "         [-0.2055, -0.2240, -0.8033, -0.8358],\n",
       "         ...,\n",
       "         [ 0.0421, -0.2011,  1.2316,  0.8858],\n",
       "         [ 0.2406, -1.3437,  0.1829,  0.9423],\n",
       "         [ 0.3222,  1.3329, -0.0996,  0.3477]],\n",
       "\n",
       "        [[ 0.4002, -0.8560,  0.5732,  1.1735],\n",
       "         [-0.1852, -0.3178,  1.0571, -0.0367],\n",
       "         [-0.2055, -0.2240, -0.8033, -0.8358],\n",
       "         ...,\n",
       "         [ 0.0421, -0.2011,  1.2316,  0.8858],\n",
       "         [ 0.2406, -1.3437,  0.1829,  0.9423],\n",
       "         [ 0.3222,  1.3329, -0.0996,  0.3477]]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 64, 5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1139, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030],\n",
       "         [ 0.1139, -1.1631, -0.4052,  ..., -1.0726, -0.5947, -0.7030],\n",
       "         [ 0.1139, -1.1631, -0.4053,  ..., -1.0727, -0.5946, -0.7031],\n",
       "         [ 0.1139, -1.1631, -0.4052,  ..., -1.0726, -0.5947, -0.7030],\n",
       "         [ 0.1140, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030]],\n",
       "\n",
       "        [[ 0.1139, -1.1631, -0.4052,  ..., -1.0726, -0.5947, -0.7030],\n",
       "         [ 0.1139, -1.1631, -0.4053,  ..., -1.0727, -0.5946, -0.7031],\n",
       "         [ 0.1139, -1.1631, -0.4052,  ..., -1.0726, -0.5947, -0.7030],\n",
       "         [ 0.1140, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030],\n",
       "         [ 0.1140, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030]],\n",
       "\n",
       "        [[ 0.1139, -1.1631, -0.4053,  ..., -1.0727, -0.5946, -0.7031],\n",
       "         [ 0.1139, -1.1631, -0.4052,  ..., -1.0726, -0.5947, -0.7030],\n",
       "         [ 0.1140, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030],\n",
       "         [ 0.1140, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030],\n",
       "         [ 0.1140, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030]],\n",
       "\n",
       "        [[ 0.1139, -1.1631, -0.4052,  ..., -1.0726, -0.5947, -0.7030],\n",
       "         [ 0.1140, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030],\n",
       "         [ 0.1140, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030],\n",
       "         [ 0.1140, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030],\n",
       "         [ 0.1140, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030]],\n",
       "\n",
       "        [[ 0.1140, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030],\n",
       "         [ 0.1140, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030],\n",
       "         [ 0.1140, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030],\n",
       "         [ 0.1140, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030],\n",
       "         [ 0.1140, -1.1631, -0.4052,  ..., -1.0725, -0.5947, -0.7030]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TFT import VariationSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = VariationSelection(64,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = v.forward(static_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(y,dim =-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = VariationSelection(64,5,context_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = f.forward(history_input,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 64, 1])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 64])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFT(\n",
       "  (tft_embed): TFT_embedding(\n",
       "    (static_cont): Linear(in_features=7, out_features=64, bias=True)\n",
       "    (static_cat): ModuleList(\n",
       "      (0): Embedding(16, 64)\n",
       "      (1): Embedding(6, 64)\n",
       "      (2): Embedding(3, 64)\n",
       "    )\n",
       "    (history_cont): Linear(in_features=11, out_features=64, bias=True)\n",
       "    (history_cat): ModuleList(\n",
       "      (0): Embedding(12, 64)\n",
       "      (1): Embedding(31, 64)\n",
       "      (2): Embedding(5, 64)\n",
       "      (3): Embedding(52, 64)\n",
       "    )\n",
       "    (future_feature): ModuleList(\n",
       "      (0): Embedding(12, 64)\n",
       "      (1): Embedding(31, 64)\n",
       "      (2): Embedding(5, 64)\n",
       "      (3): Embedding(52, 64)\n",
       "    )\n",
       "  )\n",
       "  (cs): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (linear5): Linear(in_features=64, out_features=256, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=256, out_features=4, bias=True)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-3): 4 x GRN(\n",
       "        (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (linear5): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ce): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (linear5): Linear(in_features=64, out_features=256, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=256, out_features=4, bias=True)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-3): 4 x GRN(\n",
       "        (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (linear5): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cc): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (linear5): Linear(in_features=64, out_features=256, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=256, out_features=4, bias=True)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-3): 4 x GRN(\n",
       "        (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (linear5): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ch): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (linear5): Linear(in_features=64, out_features=256, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=256, out_features=4, bias=True)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-3): 4 x GRN(\n",
       "        (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (linear5): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (history_variation): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=320, out_features=320, bias=True)\n",
       "      (linear2): Linear(in_features=320, out_features=64, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=64, out_features=320, bias=True)\n",
       "        (linear5): Linear(in_features=64, out_features=320, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=320, out_features=5, bias=True)\n",
       "      (linear_conext): Linear(in_features=64, out_features=320, bias=False)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-4): 5 x GRN(\n",
       "        (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (linear5): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (future_variation): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (linear5): Linear(in_features=64, out_features=256, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=256, out_features=4, bias=True)\n",
       "      (linear_conext): Linear(in_features=64, out_features=256, bias=False)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-3): 4 x GRN(\n",
       "        (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (linear5): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (gate_add_norm_history): Gate_Add_Norm(\n",
       "    (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (linear5): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (gate_add_norm_future): Gate_Add_Norm(\n",
       "    (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (linear5): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (GRN): GRN(\n",
       "    (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (linear5): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (droput): Dropout(p=0.0, inplace=False)\n",
       "    (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (linear_conext): Linear(in_features=64, out_features=64, bias=False)\n",
       "  )\n",
       "  (history_lstm): LSTM(64, 64, batch_first=True)\n",
       "  (future_lstm): LSTM(64, 64, batch_first=True)\n",
       "  (InterpAttention): InterpretableMultiHeadAttention(\n",
       "    (q_linear): ModuleList(\n",
       "      (0-3): 4 x Linear(in_features=64, out_features=16, bias=True)\n",
       "    )\n",
       "    (k_linear): ModuleList(\n",
       "      (0-3): 4 x Linear(in_features=64, out_features=16, bias=True)\n",
       "    )\n",
       "    (v_linear): Linear(in_features=64, out_features=7, bias=True)\n",
       "  )\n",
       "  (gate_add_norm_attention): Gate_Add_Norm(\n",
       "    (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=7, out_features=64, bias=True)\n",
       "      (linear5): Linear(in_features=7, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (attention_GRN): GRN(\n",
       "    (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (linear5): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (droput): Dropout(p=0.0, inplace=False)\n",
       "    (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (gate_add_norm_last): Gate_Add_Norm(\n",
       "    (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=2, out_features=64, bias=True)\n",
       "      (linear5): Linear(in_features=2, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (GLU): GLU(\n",
       "    (linear4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (linear5): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (output_linear): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = TFT(static_cat_feature_num_list= static_cat_feature_num_list,\n",
    "             static_cont_feature_num=static_cont_feature_num,\n",
    "             history_cat_feature_num_list= history_cat_feature_num_list,\n",
    "             history_cont_feature_num=history_cont_feature_num,\n",
    "             future_feature_list=future_feature_num,\n",
    "             seq_len = 7,\n",
    "             future_len = 2,\n",
    "\n",
    "             hidden_size=64)\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10, 5, 64])\n",
      "torch.Size([10, 2, 64])\n",
      "history_input torch.Size([10, 5, 64, 5])\n",
      "x torch.Size([10, 5, 64])\n",
      "residual torch.Size([10, 5, 64])\n",
      "gated torch.Size([10, 5, 64])\n",
      "x torch.Size([10, 2, 64])\n",
      "residual torch.Size([10, 2, 64])\n",
      "gated torch.Size([10, 2, 64])\n",
      "static_enriched torch.Size([10, 7, 64])\n",
      "attention_QKV torch.Size([10, 7, 7])\n",
      "x torch.Size([10, 7, 7])\n",
      "residual torch.Size([10, 7, 64])\n",
      "gated torch.Size([10, 7, 64])\n",
      "lstm torch.Size([10, 2, 64])\n",
      "tensor([[[-0.5423,  0.8767, -0.3074],\n",
      "         [-0.9336,  0.2998, -0.0934]],\n",
      "\n",
      "        [[-1.1175,  0.1633,  0.0638],\n",
      "         [-1.1000,  0.5756,  0.6080]],\n",
      "\n",
      "        [[-0.9320,  0.5379,  0.3814],\n",
      "         [-0.2832,  1.0623,  0.0298]],\n",
      "\n",
      "        [[-0.4654,  1.3879,  0.1780],\n",
      "         [-1.3852,  1.5010,  0.5490]],\n",
      "\n",
      "        [[-1.1674,  1.3211,  0.9434],\n",
      "         [-1.0305,  1.5124,  0.3802]],\n",
      "\n",
      "        [[-1.3750,  1.6614,  0.1139],\n",
      "         [-0.7757,  0.5982, -0.3669]],\n",
      "\n",
      "        [[-0.7253,  1.1770,  0.3864],\n",
      "         [ 0.4279,  1.4196,  0.0794]],\n",
      "\n",
      "        [[ 0.2184,  1.7452,  0.2332],\n",
      "         [ 0.5339,  1.1357, -0.3259]],\n",
      "\n",
      "        [[ 0.0676,  1.0547, -0.4285],\n",
      "         [ 0.2863,  1.1500, -0.0226]],\n",
      "\n",
      "        [[-0.3074,  1.4598,  0.3473],\n",
      "         [ 0.0397,  1.3462, -0.1094]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for static_cont_input, static_cat_input,history_cont_input, history_cat_input, future_input, prediction in loader:\n",
    "    x = emb(static_cont_input, static_cat_input,history_cont_input, history_cat_input, future_input)\n",
    "    break\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0687,  0.6977,  0.3785,  ...,  1.1539, -1.4019,  0.4181],\n",
       "         [ 1.7472, -0.7559,  1.9793,  ...,  1.4521, -1.0171, -1.8192],\n",
       "         [ 0.8419, -0.2184,  1.2573,  ..., -0.0700, -1.2749, -0.2932],\n",
       "         ...,\n",
       "         [ 1.2444, -0.4137,  1.0899,  ...,  1.6794, -1.9001, -1.0663],\n",
       "         [ 0.7266,  0.3071, -1.0389,  ...,  1.3872,  1.5878,  2.1856],\n",
       "         [ 0.7088,  1.9889,  0.0465,  ...,  1.2517,  2.2395,  0.9451]],\n",
       "\n",
       "        [[ 1.7467, -0.7221,  1.9574,  ...,  1.4453, -1.0070, -1.8417],\n",
       "         [ 0.8405, -0.1982,  1.2438,  ..., -0.0854, -1.2682, -0.3036],\n",
       "         [ 1.5748, -0.7587,  0.8706,  ...,  0.3736, -2.3626, -0.7074],\n",
       "         ...,\n",
       "         [ 1.7713,  0.1461,  0.6986,  ...,  0.3021, -1.6423, -0.8768],\n",
       "         [ 0.7476,  1.9508,  0.1232,  ...,  1.1785,  2.2025,  0.6015],\n",
       "         [-1.3652,  1.1453, -1.2450,  ...,  1.6384, -0.2929, -0.4110]],\n",
       "\n",
       "        [[ 0.8422, -0.2025,  1.2403,  ..., -0.0779, -1.2704, -0.3420],\n",
       "         [ 1.5826, -0.7608,  0.8730,  ...,  0.3760, -2.3662, -0.7331],\n",
       "         [ 1.2459, -0.4109,  1.0881,  ...,  1.6786, -1.9038, -1.0844],\n",
       "         ...,\n",
       "         [ 2.0025, -0.2604,  0.9232,  ...,  0.0334, -1.4641, -0.0807],\n",
       "         [-1.5336,  0.9927, -1.1496,  ...,  1.5139, -0.4648, -0.8792],\n",
       "         [-1.2244,  0.0468, -0.9053,  ..., -0.3483,  1.3921, -0.4443]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4802, -2.8873,  1.6067,  ...,  0.2883, -0.7956, -0.8757],\n",
       "         [ 1.2859, -1.5933,  0.7608,  ...,  0.2599, -0.9474, -1.5472],\n",
       "         [ 2.0603, -1.3548,  1.4086,  ...,  0.3156, -0.3079, -1.3382],\n",
       "         ...,\n",
       "         [ 1.4777, -1.7722,  1.4877,  ..., -0.8720, -0.0943, -0.7688],\n",
       "         [ 0.6661, -0.7565, -1.8340,  ..., -0.5521, -0.4858,  0.2310],\n",
       "         [ 0.2215,  0.3805,  0.4040,  ...,  0.8574,  0.6007,  1.0332]],\n",
       "\n",
       "        [[ 1.2724, -1.6068,  0.7763,  ...,  0.2808, -0.9603, -1.5649],\n",
       "         [ 2.0578, -1.3614,  1.4162,  ...,  0.3196, -0.3136, -1.3458],\n",
       "         [ 1.6135, -2.3373,  0.0217,  ..., -0.3187, -0.8267, -1.5873],\n",
       "         ...,\n",
       "         [ 0.4683, -1.5919,  1.2563,  ...,  0.1981, -1.1318, -0.7780],\n",
       "         [ 0.1314,  0.2581,  0.4429,  ...,  0.6952,  0.6014,  0.7275],\n",
       "         [-1.1328,  0.5234,  0.2960,  ..., -1.2502,  1.7246, -0.9288]],\n",
       "\n",
       "        [[ 2.0642, -1.3677,  1.4226,  ...,  0.3315, -0.3063, -1.3791],\n",
       "         [ 1.6181, -2.3454,  0.0260,  ..., -0.3148, -0.8185, -1.6015],\n",
       "         [ 1.4796, -1.7834,  1.4875,  ..., -0.8692, -0.0912, -0.7763],\n",
       "         ...,\n",
       "         [ 0.7424, -1.6767,  1.0490,  ...,  0.9650, -0.5436, -1.3368],\n",
       "         [-0.7459,  0.6612,  0.0032,  ..., -1.1185,  1.6277, -0.5470],\n",
       "         [-0.5352, -0.4166, -1.1061,  ..., -0.9011,  1.4314,  2.7394]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 5])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.triu(torch.full((5, 5), float('-inf')), 1).unsqueeze(0).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-hw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
