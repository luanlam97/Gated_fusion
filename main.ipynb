{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: kagglehub in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from -r requirements.txt (line 3)) (0.3.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from -r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: yfinance in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from -r requirements.txt (line 5)) (0.2.50)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from -r requirements.txt (line 6)) (1.5.2)\n",
      "Requirement already satisfied: pandas_ta in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from -r requirements.txt (line 7)) (0.3.14b0)\n",
      "Requirement already satisfied: transformers in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from -r requirements.txt (line 8)) (4.46.3)\n",
      "Collecting requests_ratelimiter (from -r requirements.txt (line 9))\n",
      "  Downloading requests_ratelimiter-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from kagglehub->-r requirements.txt (line 3)) (24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from kagglehub->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from kagglehub->-r requirements.txt (line 3)) (4.66.5)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from yfinance->-r requirements.txt (line 5)) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from yfinance->-r requirements.txt (line 5)) (5.3.0)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from yfinance->-r requirements.txt (line 5)) (4.3.6)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from yfinance->-r requirements.txt (line 5)) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from yfinance->-r requirements.txt (line 5)) (3.17.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from yfinance->-r requirements.txt (line 5)) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from yfinance->-r requirements.txt (line 5)) (1.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (0.26.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (0.4.5)\n",
      "Collecting pyrate-limiter<3.0 (from requests_ratelimiter->-r requirements.txt (line 9))\n",
      "  Downloading pyrate_limiter-2.10.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance->-r requirements.txt (line 5)) (2.6)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from html5lib>=1.1->yfinance->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from html5lib>=1.1->yfinance->-r requirements.txt (line 5)) (0.5.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers->-r requirements.txt (line 8)) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers->-r requirements.txt (line 8)) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 3)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 3)) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\luanl\\anaconda3\\envs\\dl_hw3\\lib\\site-packages (from tqdm->kagglehub->-r requirements.txt (line 3)) (0.4.6)\n",
      "Downloading requests_ratelimiter-0.7.0-py3-none-any.whl (9.3 kB)\n",
      "Downloading pyrate_limiter-2.10.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: pyrate-limiter, requests_ratelimiter\n",
      "Successfully installed pyrate-limiter-2.10.0 requests_ratelimiter-0.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from data_util import get_data_from_kaggle, restructure_date_information, get_static_df, one_label_scale_static_df, scale_stock_data\n",
    "from constant import Constant\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "from TFT import TFT_embedding, TFT, QuantilesLoss\n",
    "from data import TFT_Dataset\n",
    "from torch.utils.data import DataLoader ,random_split\n",
    "from data_util import get_feature_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFT.tft.TFT"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<constant.Constant at 0x206a9680450>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant = Constant()\n",
    "constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = 'sp500' # [forbes2000, nasdaq, nyse, sp500]\n",
    "year = '2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock = get_data_from_kaggle(market = 'sp500', start_date = f'01-01-{year}')\n",
    "# generating static df can take a while because there is a rate limit with yfinance api\n",
    "# static = get_static_df(stock,  constant.static_variables)\n",
    "\n",
    "# stock.to_csv(f'dataset/sp500_{year}.csv', index=False)\n",
    "# static.to_csv(f\"dataset/sp500_{year}_static.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = pd.read_csv(f'dataset/sp500_{year}.csv')\n",
    "static = pd.read_csv(f\"dataset/sp500_{year}_static.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted Close</th>\n",
       "      <th>Stock Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>45.740002</td>\n",
       "      <td>45.930000</td>\n",
       "      <td>1739600.0</td>\n",
       "      <td>46.750000</td>\n",
       "      <td>46.490002</td>\n",
       "      <td>44.433620</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>46.820000</td>\n",
       "      <td>46.930000</td>\n",
       "      <td>1821300.0</td>\n",
       "      <td>47.380001</td>\n",
       "      <td>47.099998</td>\n",
       "      <td>45.016628</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>46.360001</td>\n",
       "      <td>47.049999</td>\n",
       "      <td>1503700.0</td>\n",
       "      <td>47.070000</td>\n",
       "      <td>46.540001</td>\n",
       "      <td>44.481392</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>46.560001</td>\n",
       "      <td>46.630001</td>\n",
       "      <td>2883400.0</td>\n",
       "      <td>48.070000</td>\n",
       "      <td>47.990002</td>\n",
       "      <td>45.867260</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>47.910000</td>\n",
       "      <td>48.009998</td>\n",
       "      <td>2575300.0</td>\n",
       "      <td>48.560001</td>\n",
       "      <td>48.139999</td>\n",
       "      <td>46.010628</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605210</th>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>152.089996</td>\n",
       "      <td>154.220001</td>\n",
       "      <td>1964800.0</td>\n",
       "      <td>155.500000</td>\n",
       "      <td>153.050003</td>\n",
       "      <td>153.050003</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605211</th>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>149.380005</td>\n",
       "      <td>152.960007</td>\n",
       "      <td>2444100.0</td>\n",
       "      <td>153.789993</td>\n",
       "      <td>150.250000</td>\n",
       "      <td>150.250000</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605212</th>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>149.199997</td>\n",
       "      <td>150.529999</td>\n",
       "      <td>2267500.0</td>\n",
       "      <td>154.350006</td>\n",
       "      <td>153.679993</td>\n",
       "      <td>153.679993</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605213</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>152.740005</td>\n",
       "      <td>153.940002</td>\n",
       "      <td>3274900.0</td>\n",
       "      <td>156.330002</td>\n",
       "      <td>153.389999</td>\n",
       "      <td>153.389999</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605214</th>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>152.970001</td>\n",
       "      <td>154.070007</td>\n",
       "      <td>301135.0</td>\n",
       "      <td>154.470001</td>\n",
       "      <td>153.625000</td>\n",
       "      <td>153.625000</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605215 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date         Low        Open     Volume        High       Close  \\\n",
       "0       2017-01-03   45.740002   45.930000  1739600.0   46.750000   46.490002   \n",
       "1       2017-01-04   46.820000   46.930000  1821300.0   47.380001   47.099998   \n",
       "2       2017-01-05   46.360001   47.049999  1503700.0   47.070000   46.540001   \n",
       "3       2017-01-06   46.560001   46.630001  2883400.0   48.070000   47.990002   \n",
       "4       2017-01-09   47.910000   48.009998  2575300.0   48.560001   48.139999   \n",
       "...            ...         ...         ...        ...         ...         ...   \n",
       "605210  2022-12-06  152.089996  154.220001  1964800.0  155.500000  153.050003   \n",
       "605211  2022-12-07  149.380005  152.960007  2444100.0  153.789993  150.250000   \n",
       "605212  2022-12-08  149.199997  150.529999  2267500.0  154.350006  153.679993   \n",
       "605213  2022-12-09  152.740005  153.940002  3274900.0  156.330002  153.389999   \n",
       "605214  2022-12-12  152.970001  154.070007   301135.0  154.470001  153.625000   \n",
       "\n",
       "        Adjusted Close Stock Name  \n",
       "0            44.433620          A  \n",
       "1            45.016628          A  \n",
       "2            44.481392          A  \n",
       "3            45.867260          A  \n",
       "4            46.010628          A  \n",
       "...                ...        ...  \n",
       "605210      153.050003        ZTS  \n",
       "605211      150.250000        ZTS  \n",
       "605212      153.679993        ZTS  \n",
       "605213      153.389999        ZTS  \n",
       "605214      153.625000        ZTS  \n",
       "\n",
       "[605215 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>industry</th>\n",
       "      <th>sector</th>\n",
       "      <th>country</th>\n",
       "      <th>beta</th>\n",
       "      <th>marketCap</th>\n",
       "      <th>bookValue</th>\n",
       "      <th>dividendRate</th>\n",
       "      <th>dividendYield</th>\n",
       "      <th>fiveYearAvgDividendYield</th>\n",
       "      <th>debtToEquity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.072</td>\n",
       "      <td>39891210240</td>\n",
       "      <td>20.530</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.66</td>\n",
       "      <td>52.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <td>Airlines</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.399</td>\n",
       "      <td>9680030720</td>\n",
       "      <td>-7.387</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>Specialty Retail</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.194</td>\n",
       "      <td>2744477440</td>\n",
       "      <td>42.340</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>2.44</td>\n",
       "      <td>171.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>Consumer Electronics</td>\n",
       "      <td>Technology</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.240</td>\n",
       "      <td>3622499778560</td>\n",
       "      <td>3.767</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.62</td>\n",
       "      <td>209.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>Drug Manufacturers - General</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.613</td>\n",
       "      <td>322113306624</td>\n",
       "      <td>3.413</td>\n",
       "      <td>6.56</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>4.13</td>\n",
       "      <td>1174.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XYL</th>\n",
       "      <td>Specialty Industrial Machinery</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.050</td>\n",
       "      <td>30846726144</td>\n",
       "      <td>43.593</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>1.16</td>\n",
       "      <td>19.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YUM</th>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.095</td>\n",
       "      <td>38885851136</td>\n",
       "      <td>-27.407</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBH</th>\n",
       "      <td>Medical Devices</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.021</td>\n",
       "      <td>21979760640</td>\n",
       "      <td>61.997</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.75</td>\n",
       "      <td>53.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZION</th>\n",
       "      <td>Banks - Regional</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.060</td>\n",
       "      <td>8874271744</td>\n",
       "      <td>40.251</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTS</th>\n",
       "      <td>Drug Manufacturers - Specialty &amp; Generic</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.896</td>\n",
       "      <td>80394125312</td>\n",
       "      <td>11.591</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.68</td>\n",
       "      <td>129.442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      industry              sector  \\\n",
       "A                       Diagnostics & Research          Healthcare   \n",
       "AAL                                   Airlines         Industrials   \n",
       "AAP                           Specialty Retail   Consumer Cyclical   \n",
       "AAPL                      Consumer Electronics          Technology   \n",
       "ABBV              Drug Manufacturers - General          Healthcare   \n",
       "...                                        ...                 ...   \n",
       "XYL             Specialty Industrial Machinery         Industrials   \n",
       "YUM                                Restaurants   Consumer Cyclical   \n",
       "ZBH                            Medical Devices          Healthcare   \n",
       "ZION                          Banks - Regional  Financial Services   \n",
       "ZTS   Drug Manufacturers - Specialty & Generic          Healthcare   \n",
       "\n",
       "            country   beta      marketCap  bookValue  dividendRate  \\\n",
       "A     United States  1.072    39891210240     20.530          0.99   \n",
       "AAL   United States  1.399     9680030720     -7.387          0.00   \n",
       "AAP   United States  1.194     2744477440     42.340          1.00   \n",
       "AAPL  United States  1.240  3622499778560      3.767          1.00   \n",
       "ABBV  United States  0.613   322113306624      3.413          6.56   \n",
       "...             ...    ...            ...        ...           ...   \n",
       "XYL   United States  1.050    30846726144     43.593          1.44   \n",
       "YUM   United States  1.095    38885851136    -27.407          2.68   \n",
       "ZBH   United States  1.021    21979760640     61.997          0.96   \n",
       "ZION  United States  1.060     8874271744     40.251          1.72   \n",
       "ZTS   United States  0.896    80394125312     11.591          1.73   \n",
       "\n",
       "      dividendYield  fiveYearAvgDividendYield  debtToEquity  \n",
       "A            0.0074                      0.66        52.787  \n",
       "AAL          0.0000                      1.27         0.000  \n",
       "AAP          0.0243                      2.44       171.801  \n",
       "AAPL         0.0042                      0.62       209.059  \n",
       "ABBV         0.0359                      4.13      1174.815  \n",
       "...             ...                       ...           ...  \n",
       "XYL          0.0114                      1.16        19.840  \n",
       "YUM          0.0193                      1.81         0.000  \n",
       "ZBH          0.0086                      0.75        53.611  \n",
       "ZION         0.0284                      3.47         0.000  \n",
       "ZTS          0.0099                      0.68       129.442  \n",
       "\n",
       "[408 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Consumer Electronics', 'Technology', 'United States', 1.24,\n",
       "       3622499778560, 3.767, 1.0, 0.0042, 0.62, 209.059], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static.loc[\"AAPL\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tickers = static.index\n",
    "stock = stock[stock['Stock Name'].isin(valid_tickers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = stock.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted Close</th>\n",
       "      <th>Stock Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>0.113930</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>0.091776</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.188017</td>\n",
       "      <td>0.009938</td>\n",
       "      <td>0.011296</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>0.015598</td>\n",
       "      <td>0.166526</td>\n",
       "      <td>0.013627</td>\n",
       "      <td>0.012426</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605210</th>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>0.518709</td>\n",
       "      <td>0.522872</td>\n",
       "      <td>0.132240</td>\n",
       "      <td>0.522823</td>\n",
       "      <td>0.516862</td>\n",
       "      <td>0.526255</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605211</th>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>0.504664</td>\n",
       "      <td>0.516396</td>\n",
       "      <td>0.170338</td>\n",
       "      <td>0.514121</td>\n",
       "      <td>0.502468</td>\n",
       "      <td>0.511865</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605212</th>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>0.503731</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.156301</td>\n",
       "      <td>0.516971</td>\n",
       "      <td>0.520101</td>\n",
       "      <td>0.529492</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605213</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>0.522077</td>\n",
       "      <td>0.521433</td>\n",
       "      <td>0.236376</td>\n",
       "      <td>0.527047</td>\n",
       "      <td>0.518610</td>\n",
       "      <td>0.528002</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605214</th>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>0.523269</td>\n",
       "      <td>0.522101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517582</td>\n",
       "      <td>0.519818</td>\n",
       "      <td>0.529210</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605215 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date       Low      Open    Volume      High     Close  \\\n",
       "0       2017-01-03  0.000000  0.000000  0.108231  0.000000  0.000000   \n",
       "1       2017-01-04  0.008217  0.007499  0.113930  0.004743  0.004594   \n",
       "2       2017-01-05  0.004717  0.008399  0.091776  0.002409  0.000377   \n",
       "3       2017-01-06  0.006239  0.005249  0.188017  0.009938  0.011296   \n",
       "4       2017-01-09  0.016511  0.015598  0.166526  0.013627  0.012426   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "605210  2022-12-06  0.518709  0.522872  0.132240  0.522823  0.516862   \n",
       "605211  2022-12-07  0.504664  0.516396  0.170338  0.514121  0.502468   \n",
       "605212  2022-12-08  0.503731  0.503906  0.156301  0.516971  0.520101   \n",
       "605213  2022-12-09  0.522077  0.521433  0.236376  0.527047  0.518610   \n",
       "605214  2022-12-12  0.523269  0.522101  0.000000  0.517582  0.519818   \n",
       "\n",
       "        Adjusted Close Stock Name  \n",
       "0             0.000000          A  \n",
       "1             0.004368          A  \n",
       "2             0.000358          A  \n",
       "3             0.010740          A  \n",
       "4             0.011814          A  \n",
       "...                ...        ...  \n",
       "605210        0.526255        ZTS  \n",
       "605211        0.511865        ZTS  \n",
       "605212        0.529492        ZTS  \n",
       "605213        0.528002        ZTS  \n",
       "605214        0.529210        ZTS  \n",
       "\n",
       "[605215 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_scaled, stock_scalar = scale_stock_data(stock, constant.columns_to_scale)\n",
    "stock_scaled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted Close</th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Day of The Week</th>\n",
       "      <th>Week of The Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>0.113930</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>0.091776</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.188017</td>\n",
       "      <td>0.009938</td>\n",
       "      <td>0.011296</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016511</td>\n",
       "      <td>0.015598</td>\n",
       "      <td>0.166526</td>\n",
       "      <td>0.013627</td>\n",
       "      <td>0.012426</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605210</th>\n",
       "      <td>0.518709</td>\n",
       "      <td>0.522872</td>\n",
       "      <td>0.132240</td>\n",
       "      <td>0.522823</td>\n",
       "      <td>0.516862</td>\n",
       "      <td>0.526255</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605211</th>\n",
       "      <td>0.504664</td>\n",
       "      <td>0.516396</td>\n",
       "      <td>0.170338</td>\n",
       "      <td>0.514121</td>\n",
       "      <td>0.502468</td>\n",
       "      <td>0.511865</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605212</th>\n",
       "      <td>0.503731</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.156301</td>\n",
       "      <td>0.516971</td>\n",
       "      <td>0.520101</td>\n",
       "      <td>0.529492</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605213</th>\n",
       "      <td>0.522077</td>\n",
       "      <td>0.521433</td>\n",
       "      <td>0.236376</td>\n",
       "      <td>0.527047</td>\n",
       "      <td>0.518610</td>\n",
       "      <td>0.528002</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605214</th>\n",
       "      <td>0.523269</td>\n",
       "      <td>0.522101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517582</td>\n",
       "      <td>0.519818</td>\n",
       "      <td>0.529210</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605215 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Low      Open    Volume      High     Close  Adjusted Close  \\\n",
       "0       0.000000  0.000000  0.108231  0.000000  0.000000        0.000000   \n",
       "1       0.008217  0.007499  0.113930  0.004743  0.004594        0.004368   \n",
       "2       0.004717  0.008399  0.091776  0.002409  0.000377        0.000358   \n",
       "3       0.006239  0.005249  0.188017  0.009938  0.011296        0.010740   \n",
       "4       0.016511  0.015598  0.166526  0.013627  0.012426        0.011814   \n",
       "...          ...       ...       ...       ...       ...             ...   \n",
       "605210  0.518709  0.522872  0.132240  0.522823  0.516862        0.526255   \n",
       "605211  0.504664  0.516396  0.170338  0.514121  0.502468        0.511865   \n",
       "605212  0.503731  0.503906  0.156301  0.516971  0.520101        0.529492   \n",
       "605213  0.522077  0.521433  0.236376  0.527047  0.518610        0.528002   \n",
       "605214  0.523269  0.522101  0.000000  0.517582  0.519818        0.529210   \n",
       "\n",
       "       Stock Name  Month  Day  Day of The Week  Week of The Year  \n",
       "0               A      0    2                1                 0  \n",
       "1               A      0    3                2                 0  \n",
       "2               A      0    4                3                 0  \n",
       "3               A      0    5                4                 0  \n",
       "4               A      0    8                0                 1  \n",
       "...           ...    ...  ...              ...               ...  \n",
       "605210        ZTS     11    5                1                48  \n",
       "605211        ZTS     11    6                2                48  \n",
       "605212        ZTS     11    7                3                48  \n",
       "605213        ZTS     11    8                4                48  \n",
       "605214        ZTS     11   11                0                49  \n",
       "\n",
       "[605215 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = restructure_date_information(stock_scaled)\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = one_label_scale_static_df(static,constant.static_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cat_feature_num_list, history_cont_feature_num = get_feature_length(processed_df, constant.feature_variables)\n",
    "static_cat_feature_num_list , static_cont_feature_num  = get_feature_length(static, constant.static_variables)\n",
    "future_cat_feature_num_list , _                        = get_feature_length(processed_df, constant.future_feature)\n",
    "_                           , prediction_con           = get_feature_length(processed_df, constant.prediction_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([12, 31, 5, 53], 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_cat_feature_num_list, history_cont_feature_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_length = 90\n",
    "prediction_length = 15\n",
    "hidden_size = 128\n",
    "batch_size = 128\n",
    "dropout = .2\n",
    "num_head = 4\n",
    "lr= 0.0001\n",
    "momentum=0.9\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1\n",
    "split_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft_Dataset = TFT_Dataset(stock_df= processed_df , \n",
    "                        static_df=static_df,\n",
    "                        constant_variable=constant, \n",
    "                        history_length= history_length, \n",
    "                        prediction_length= prediction_length, \n",
    "                        device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * tft_Dataset.__len__())\n",
    "test_size = len(tft_Dataset) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = random_split(tft_Dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 7]) cuda:0\n"
     ]
    }
   ],
   "source": [
    "count =0\n",
    "for static_cont_input, static_cat_input,history_cont_input, history_cat_input, future_input, prediction in train_loader:\n",
    "    break\n",
    "print(static_cont_input.size(), static_cont_input.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFT(\n",
       "  (tft_embed): TFT_embedding(\n",
       "    (static_cont): Linear(in_features=7, out_features=128, bias=True)\n",
       "    (static_cat): ModuleList(\n",
       "      (0): Embedding(108, 128)\n",
       "      (1-2): 2 x Embedding(12, 128)\n",
       "    )\n",
       "    (history_cont): Linear(in_features=4, out_features=128, bias=True)\n",
       "    (history_cat): ModuleList(\n",
       "      (0): Embedding(12, 128)\n",
       "      (1): Embedding(31, 128)\n",
       "      (2): Embedding(5, 128)\n",
       "      (3): Embedding(53, 128)\n",
       "    )\n",
       "    (future_feature): ModuleList(\n",
       "      (0): Embedding(12, 128)\n",
       "      (1): Embedding(31, 128)\n",
       "      (2): Embedding(5, 128)\n",
       "      (3): Embedding(53, 128)\n",
       "    )\n",
       "  )\n",
       "  (cs): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-3): 4 x GRN(\n",
       "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ce): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-3): 4 x GRN(\n",
       "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cc): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-3): 4 x GRN(\n",
       "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ch): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-3): 4 x GRN(\n",
       "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (history_variation): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=640, out_features=640, bias=True)\n",
       "      (linear2): Linear(in_features=640, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=640, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=640, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=640, out_features=5, bias=True)\n",
       "      (linear_conext): Linear(in_features=128, out_features=640, bias=False)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-4): 5 x GRN(\n",
       "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (future_variation): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "      (linear_conext): Linear(in_features=128, out_features=512, bias=False)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-3): 4 x GRN(\n",
       "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (gate_add_norm_history): Gate_Add_Norm(\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (gate_add_norm_future): Gate_Add_Norm(\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (GRN): GRN(\n",
       "    (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (droput): Dropout(p=0.0, inplace=False)\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (linear_conext): Linear(in_features=128, out_features=128, bias=False)\n",
       "  )\n",
       "  (history_lstm): LSTM(128, 128, batch_first=True)\n",
       "  (future_lstm): LSTM(128, 128, batch_first=True)\n",
       "  (history_layernorm): LayerNorm((128,), eps=0.2, elementwise_affine=True)\n",
       "  (future_layernorm): LayerNorm((128,), eps=0.2, elementwise_affine=True)\n",
       "  (InterpAttention): InterpretableMultiHeadAttention(\n",
       "    (q_linear): ModuleList(\n",
       "      (0-3): 4 x Linear(in_features=128, out_features=32, bias=True)\n",
       "    )\n",
       "    (k_linear): ModuleList(\n",
       "      (0-3): 4 x Linear(in_features=128, out_features=32, bias=True)\n",
       "    )\n",
       "    (v_linear): Linear(in_features=128, out_features=105, bias=True)\n",
       "  )\n",
       "  (attention_layernorm): LayerNorm((105,), eps=0.2, elementwise_affine=True)\n",
       "  (gate_add_norm_attention): Gate_Add_Norm(\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=105, out_features=128, bias=True)\n",
       "      (linear5): Linear(in_features=105, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (attention_GRN): GRN(\n",
       "    (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (droput): Dropout(p=0.0, inplace=False)\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (gate_add_norm_last): Gate_Add_Norm(\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=15, out_features=128, bias=True)\n",
       "      (linear5): Linear(in_features=15, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (GLU): GLU(\n",
       "    (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (output_linear): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TFT(static_cat_feature_num_list= static_cat_feature_num_list,\n",
    "            static_cont_feature_num=static_cont_feature_num,\n",
    "            history_cat_feature_num_list= history_cat_feature_num_list,\n",
    "            history_cont_feature_num=history_cont_feature_num,\n",
    "            future_cat_feature_num_list=future_cat_feature_num_list,\n",
    "            history_len = history_length,\n",
    "            future_len = prediction_length,\n",
    "            dropout= dropout,\n",
    "            num_head = num_head,\n",
    "            hidden_size = hidden_size,\n",
    "            device = device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = QuantilesLoss( device=device)\n",
    "loss_function.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 0,  Loss: 0.7370415329933167\n",
      "Epoch: 1, Batch: 1000,  Loss: 0.06530316919088364\n",
      "Epoch: 1, Batch: 2000,  Loss: 0.05760008469223976\n",
      "Epoch: 1, Batch: 3000,  Loss: 0.05004086717963219\n",
      "###########################\n",
      "Epoch: 1,  Loss: 0.0460890531539917\n",
      "Epoch: 2, Batch: 0,  Loss: 0.046429745852947235\n",
      "Epoch: 2, Batch: 1000,  Loss: 0.041177473962306976\n",
      "Epoch: 2, Batch: 2000,  Loss: 0.04416148364543915\n",
      "Epoch: 2, Batch: 3000,  Loss: 0.047361984848976135\n",
      "###########################\n",
      "Epoch: 2,  Loss: 0.03851417452096939\n",
      "Epoch: 3, Batch: 0,  Loss: 0.040274303406476974\n",
      "Epoch: 3, Batch: 1000,  Loss: 0.033386025577783585\n",
      "Epoch: 3, Batch: 2000,  Loss: 0.039808087050914764\n",
      "Epoch: 3, Batch: 3000,  Loss: 0.03599719703197479\n",
      "###########################\n",
      "Epoch: 3,  Loss: 0.03329778462648392\n",
      "Epoch: 4, Batch: 0,  Loss: 0.03289635479450226\n",
      "Epoch: 4, Batch: 1000,  Loss: 0.03345059975981712\n",
      "Epoch: 4, Batch: 2000,  Loss: 0.03366268426179886\n",
      "Epoch: 4, Batch: 3000,  Loss: 0.03143458813428879\n",
      "###########################\n",
      "Epoch: 4,  Loss: 0.03167574852705002\n",
      "Epoch: 5, Batch: 0,  Loss: 0.03440357744693756\n",
      "Epoch: 5, Batch: 1000,  Loss: 0.03358960896730423\n",
      "Epoch: 5, Batch: 2000,  Loss: 0.03679494932293892\n",
      "Epoch: 5, Batch: 3000,  Loss: 0.03134956955909729\n",
      "###########################\n",
      "Epoch: 5,  Loss: 0.032883625477552414\n",
      "Epoch: 6, Batch: 0,  Loss: 0.03280980885028839\n",
      "Epoch: 6, Batch: 1000,  Loss: 0.03063018247485161\n",
      "Epoch: 6, Batch: 2000,  Loss: 0.03148715943098068\n",
      "Epoch: 6, Batch: 3000,  Loss: 0.02758760005235672\n",
      "###########################\n",
      "Epoch: 6,  Loss: 0.029009979218244553\n",
      "Epoch: 7, Batch: 0,  Loss: 0.03211735188961029\n",
      "Epoch: 7, Batch: 1000,  Loss: 0.03879242390394211\n",
      "Epoch: 7, Batch: 2000,  Loss: 0.029456553980708122\n",
      "Epoch: 7, Batch: 3000,  Loss: 0.03064623475074768\n",
      "###########################\n",
      "Epoch: 7,  Loss: 0.02839764580130577\n",
      "Epoch: 8, Batch: 0,  Loss: 0.030828164890408516\n",
      "Epoch: 8, Batch: 1000,  Loss: 0.030831340700387955\n",
      "Epoch: 8, Batch: 2000,  Loss: 0.025741424411535263\n",
      "Epoch: 8, Batch: 3000,  Loss: 0.030184341594576836\n",
      "###########################\n",
      "Epoch: 8,  Loss: 0.030851036310195923\n",
      "Epoch: 9, Batch: 0,  Loss: 0.030118515715003014\n",
      "Epoch: 9, Batch: 1000,  Loss: 0.026098957285284996\n",
      "Epoch: 9, Batch: 2000,  Loss: 0.030129458755254745\n",
      "Epoch: 9, Batch: 3000,  Loss: 0.0301088634878397\n",
      "###########################\n",
      "Epoch: 9,  Loss: 0.028091154992580414\n",
      "Epoch: 10, Batch: 0,  Loss: 0.026893723756074905\n",
      "Epoch: 10, Batch: 1000,  Loss: 0.027504421770572662\n",
      "Epoch: 10, Batch: 2000,  Loss: 0.029567189514636993\n",
      "Epoch: 10, Batch: 3000,  Loss: 0.026914730668067932\n",
      "###########################\n",
      "Epoch: 10,  Loss: 0.031197570264339447\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "batch_loss = [] \n",
    "for epoch in range(num_epochs):\n",
    "    for i, (static_cont_input, static_cat_input,history_cont_input, history_cat_input, future_input, prediction) in enumerate(train_loader):\n",
    "        predicted = model(static_cont_input, static_cat_input,history_cont_input, history_cat_input, future_input)\n",
    "        optimizer.zero_grad()\n",
    "        losses = loss_function(predicted = predicted, targets = prediction)\n",
    "        loss = losses.sum()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        if i % 1000 == 0:\n",
    "            print(f'Epoch: {epoch+1}, Batch: {i},  Loss: {loss.item()}')\n",
    "    batch_loss.append(loss.item())\n",
    "    print(\"###########################\")\n",
    "    print(f'Epoch: {epoch+1},  Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), f\"tft_model_{year}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(batch_loss))\n",
    "plt.plot(x, batch_loss)\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFT(static_cat_feature_num_list= static_cat_feature_num_list,\n",
    "            static_cont_feature_num=static_cont_feature_num,\n",
    "            history_cat_feature_num_list= history_cat_feature_num_list,\n",
    "            history_cont_feature_num=history_cont_feature_num,\n",
    "            future_cat_feature_num_list=future_cat_feature_num_list,\n",
    "            history_len = history_length,\n",
    "            future_len = prediction_length,\n",
    "            dropout= dropout,\n",
    "            num_head = num_head,\n",
    "            hidden_size = hidden_size,\n",
    "            device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'tft_model_{year}.pth', weights_only=True))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "count = 0\n",
    "err = 0\n",
    "with torch.no_grad():\n",
    "    for i, (static_cont_input, static_cat_input,history_cont_input, history_cat_input, future_input, prediction) in enumerate(test_loader):\n",
    "        predicted = model(static_cont_input, static_cat_input,history_cont_input, history_cat_input, future_input)\n",
    "\n",
    "        diff = (prediction.squeeze(-1) - predicted[:,:,1])**2\n",
    "        err += diff.sum()\n",
    "        count += diff.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.07693053781986237\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: \" , (err/count).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcount\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, hidden_size,n_head,q_seq_len, k_v_seq_len, device):\n",
    "        super().__init__()\n",
    "        self.n_head = n_head\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_hidden_size = self.hidden_size//self.n_head\n",
    "        self.div = self.attention_hidden_size**-0.5\n",
    "        self.mask = torch.triu(torch.full((q_seq_len, k_v_seq_len), float('-inf')), 1).to(device)\n",
    "        self.q_linear = nn.ModuleList(\n",
    "                            [nn.Linear(hidden_size, self.attention_hidden_size)\n",
    "                             for i in range(self.n_head)])\n",
    "\n",
    "        self.k_linear = nn.ModuleList(\n",
    "                            [nn.Linear(hidden_size, self.attention_hidden_size)\n",
    "                             for i in range(self.n_head)])\n",
    "        self.v_linear = nn.Linear(hidden_size, q_seq_len)\n",
    "\n",
    "        self.attention_output_linear = nn.Linear(q_seq_len, self.hidden_size)\n",
    "        self.q_residual = nn.Linear(hidden_size, self.hidden_size)\n",
    "\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "\n",
    "        q_list = [q_linear(q) for q_linear in self.q_linear]\n",
    "        k_list = [torch.transpose(k_linear(k),1,2) for k_linear in self.k_linear]\n",
    "        v = self.v_linear(v)\n",
    "        attention_QK = [torch.matmul(q, k) for q,k in zip(q_list,k_list)]\n",
    "\n",
    "        print(attention_QK[0].size(), self.mask.size())\n",
    "        attention_QK = [F.softmax(torch.mul(attention, self.div) + self.mask, dim =-1) \n",
    "                        for i, attention in enumerate(attention_QK)]\n",
    "        attention_QKV = [torch.matmul(attention, v) for attention in attention_QK]\n",
    "        attention_QKV = torch.stack(attention_QKV, dim=-1)\n",
    "        attention_QKV = torch.mean(attention_QKV, dim=-1) \n",
    "\n",
    "        q_residual = self.q_residual(q)\n",
    "        attention_output = self.attention_output_linear(attention_QKV)\n",
    "        q_sigmoid = self.sigmoid(q_residual)\n",
    "\n",
    "        output = attention_output * q_sigmoid\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossAttention(\n",
       "  (q_linear): ModuleList(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (k_linear): ModuleList(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (v_linear): Linear(in_features=64, out_features=7, bias=True)\n",
       "  (attention_output_linear): Linear(in_features=7, out_features=64, bias=True)\n",
       "  (q_residual): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross = CrossAttention( hidden_size = 64,n_head = 1 ,q_seq_len=  7 , k_v_seq_len=5 ,device= device)\n",
    "cross.to(device)\n",
    "cross2 = CrossAttention( hidden_size = 64,n_head = 1 ,q_seq_len=  7 , k_v_seq_len=12 ,device= device)\n",
    "cross2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, seq, hidden_size = 32, 7 , 64\n",
    "q = torch.rand(batch, seq, hidden_size, device=device)\n",
    "batch, seq, hidden_size = 32, 5 , 64\n",
    "k,v = torch.rand(batch, seq, hidden_size, device=device), torch.rand(batch, seq, hidden_size, device=device)\n",
    "\n",
    "batch, seq, hidden_size = 32, 12 , 64\n",
    "k_2,v_2 = torch.rand(batch, seq, hidden_size, device=device), torch.rand(batch, seq, hidden_size, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 7, 5]) torch.Size([7, 5])\n"
     ]
    }
   ],
   "source": [
    "out = cross(q,k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 7, 12]) torch.Size([7, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 7, 64])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross2(out, k_2,v_2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossFusion(nn.Module):\n",
    "    def __init__(self, n_head, num_model, seq_list, hidden_size ,device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cross_list = nn.ModuleList(\n",
    "                            [CrossAttention(n_head = n_head, q_seq_len= seq_list[0] , k_v_seq_len=seq_list[i+1]  ,hidden_size = hidden_size, device= device     )\n",
    "                             for i in range(num_model-1)\n",
    "                             ])\n",
    "        \n",
    "    def forward(self, model_output_list):\n",
    "        q = model_output_list[0]\n",
    "\n",
    "        for i, cross in enumerate(self.cross_list):\n",
    "            q = cross(q, k=model_output_list[i+1], v=model_output_list[i+1])\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossFusion(\n",
       "  (cross_list): ModuleList(\n",
       "    (0-1): 2 x CrossAttention(\n",
       "      (q_linear): ModuleList(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (k_linear): ModuleList(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (v_linear): Linear(in_features=64, out_features=7, bias=True)\n",
       "      (attention_output_linear): Linear(in_features=7, out_features=64, bias=True)\n",
       "      (q_residual): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = CrossFusion(n_head = 1 , num_model=3,seq_list= [7,5,12], hidden_size=64,device=device )\n",
    "x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 7, 5]) torch.Size([7, 5])\n",
      "torch.Size([32, 7, 12]) torch.Size([7, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0110, -0.1903,  0.0261,  ...,  0.0489,  0.3566, -0.0579],\n",
       "         [-0.0236, -0.2048,  0.0566,  ...,  0.0444,  0.3262, -0.0403],\n",
       "         [-0.0311, -0.1687,  0.0480,  ...,  0.0373,  0.2983, -0.0593],\n",
       "         ...,\n",
       "         [-0.0106, -0.1697,  0.0370,  ...,  0.0496,  0.2958, -0.0314],\n",
       "         [-0.0200, -0.1619,  0.0303,  ...,  0.0443,  0.2933, -0.0435],\n",
       "         [-0.0246, -0.1644,  0.0386,  ...,  0.0383,  0.2915, -0.0399]],\n",
       "\n",
       "        [[-0.0973, -0.1757,  0.0359,  ..., -0.0096,  0.2621, -0.0943],\n",
       "         [-0.0170, -0.1675, -0.0283,  ...,  0.0605,  0.2745, -0.0756],\n",
       "         [-0.0457, -0.1814, -0.0095,  ...,  0.0439,  0.2913, -0.0891],\n",
       "         ...,\n",
       "         [-0.0406, -0.1841,  0.0193,  ...,  0.0354,  0.3138, -0.0440],\n",
       "         [-0.0414, -0.1947,  0.0239,  ...,  0.0323,  0.3180, -0.0366],\n",
       "         [-0.0407, -0.1916,  0.0181,  ...,  0.0340,  0.3210, -0.0410]],\n",
       "\n",
       "        [[-0.0152, -0.1895,  0.0283,  ...,  0.0387,  0.2900, -0.0363],\n",
       "         [-0.0616, -0.1903,  0.0700,  ...,  0.0103,  0.2813, -0.0559],\n",
       "         [-0.0827, -0.1692,  0.0503,  ...,  0.0015,  0.2683, -0.0849],\n",
       "         ...,\n",
       "         [-0.0443, -0.1426,  0.0435,  ...,  0.0193,  0.2683, -0.0702],\n",
       "         [-0.0482, -0.1467,  0.0229,  ...,  0.0253,  0.2724, -0.0780],\n",
       "         [-0.0504, -0.1646,  0.0146,  ...,  0.0306,  0.2803, -0.0791]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0682, -0.1576, -0.0517,  ...,  0.0421,  0.2935, -0.0974],\n",
       "         [-0.0482, -0.1851, -0.0282,  ...,  0.0539,  0.2897, -0.0794],\n",
       "         [-0.0260, -0.2187, -0.0430,  ...,  0.0707,  0.3061, -0.0635],\n",
       "         ...,\n",
       "         [-0.0207, -0.2068, -0.0243,  ...,  0.0733,  0.2961, -0.0411],\n",
       "         [-0.0383, -0.1956, -0.0008,  ...,  0.0542,  0.2846, -0.0373],\n",
       "         [-0.0487, -0.1906,  0.0103,  ...,  0.0384,  0.2885, -0.0464]],\n",
       "\n",
       "        [[-0.0388, -0.2010,  0.0445,  ...,  0.0362,  0.3128,  0.0128],\n",
       "         [-0.0383, -0.1942,  0.1008,  ...,  0.0299,  0.2762,  0.0262],\n",
       "         [-0.0379, -0.1734,  0.1171,  ...,  0.0168,  0.2845,  0.0220],\n",
       "         ...,\n",
       "         [-0.0324, -0.1891,  0.1109,  ...,  0.0187,  0.3046,  0.0273],\n",
       "         [-0.0299, -0.1788,  0.0906,  ...,  0.0225,  0.2974,  0.0121],\n",
       "         [-0.0280, -0.1827,  0.0740,  ...,  0.0269,  0.3042, -0.0091]],\n",
       "\n",
       "        [[-0.0855, -0.2095,  0.0589,  ...,  0.0159,  0.3069, -0.0186],\n",
       "         [-0.0327, -0.2034,  0.0104,  ...,  0.0557,  0.2991,  0.0081],\n",
       "         [-0.0214, -0.1844,  0.0033,  ...,  0.0605,  0.2983, -0.0051],\n",
       "         ...,\n",
       "         [-0.0380, -0.1897,  0.0016,  ...,  0.0474,  0.2939, -0.0386],\n",
       "         [-0.0389, -0.1717,  0.0094,  ...,  0.0368,  0.2936, -0.0399],\n",
       "         [-0.0312, -0.1772,  0.0065,  ...,  0.0415,  0.2988, -0.0352]]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x([q,k,k_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_hw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
