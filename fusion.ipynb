{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luan\\Documents\\DL\\TFT\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from data_util import get_data_from_kaggle, restructure_date_information, get_static_df, one_label_scale_static_df, scale_stock_data\n",
    "from constant import Constant\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "from TFT import TFT_embedding, TFT, QuantilesLoss\n",
    "from data import TFT_Dataset\n",
    "from torch.utils.data import DataLoader ,random_split\n",
    "from data_util import get_feature_length\n",
    "from Fusion import CrossAttention\n",
    "from Autoformer import Autoformer\n",
    "from torch import nn\n",
    "from Fusion import Model_Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFT.tft.TFT"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<constant.Constant at 0x15248146c90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant = Constant()\n",
    "constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = 'sp500' # [forbes2000, nasdaq, nyse, sp500]\n",
    "year = '2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock = get_data_from_kaggle(market = 'sp500', start_date = f'01-01-{year}')\n",
    "# generating static df can take a while because there is a rate limit with yfinance api\n",
    "# static = get_static_df(stock,  constant.static_variables)\n",
    "\n",
    "# stock.to_csv(f'dataset/sp500_{year}.csv', index=False)\n",
    "# static.to_csv(f\"dataset/sp500_{year}_static.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = pd.read_csv(f'dataset/sp500_{year}.csv')\n",
    "static = pd.read_csv(f\"dataset/sp500_{year}_static.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted Close</th>\n",
       "      <th>Stock Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>45.740002</td>\n",
       "      <td>45.930000</td>\n",
       "      <td>1739600.0</td>\n",
       "      <td>46.750000</td>\n",
       "      <td>46.490002</td>\n",
       "      <td>44.433620</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>46.820000</td>\n",
       "      <td>46.930000</td>\n",
       "      <td>1821300.0</td>\n",
       "      <td>47.380001</td>\n",
       "      <td>47.099998</td>\n",
       "      <td>45.016628</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>46.360001</td>\n",
       "      <td>47.049999</td>\n",
       "      <td>1503700.0</td>\n",
       "      <td>47.070000</td>\n",
       "      <td>46.540001</td>\n",
       "      <td>44.481392</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>46.560001</td>\n",
       "      <td>46.630001</td>\n",
       "      <td>2883400.0</td>\n",
       "      <td>48.070000</td>\n",
       "      <td>47.990002</td>\n",
       "      <td>45.867260</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>47.910000</td>\n",
       "      <td>48.009998</td>\n",
       "      <td>2575300.0</td>\n",
       "      <td>48.560001</td>\n",
       "      <td>48.139999</td>\n",
       "      <td>46.010628</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605210</th>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>152.089996</td>\n",
       "      <td>154.220001</td>\n",
       "      <td>1964800.0</td>\n",
       "      <td>155.500000</td>\n",
       "      <td>153.050003</td>\n",
       "      <td>153.050003</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605211</th>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>149.380005</td>\n",
       "      <td>152.960007</td>\n",
       "      <td>2444100.0</td>\n",
       "      <td>153.789993</td>\n",
       "      <td>150.250000</td>\n",
       "      <td>150.250000</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605212</th>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>149.199997</td>\n",
       "      <td>150.529999</td>\n",
       "      <td>2267500.0</td>\n",
       "      <td>154.350006</td>\n",
       "      <td>153.679993</td>\n",
       "      <td>153.679993</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605213</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>152.740005</td>\n",
       "      <td>153.940002</td>\n",
       "      <td>3274900.0</td>\n",
       "      <td>156.330002</td>\n",
       "      <td>153.389999</td>\n",
       "      <td>153.389999</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605214</th>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>152.970001</td>\n",
       "      <td>154.070007</td>\n",
       "      <td>301135.0</td>\n",
       "      <td>154.470001</td>\n",
       "      <td>153.625000</td>\n",
       "      <td>153.625000</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605215 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date         Low        Open     Volume        High       Close  \\\n",
       "0       2017-01-03   45.740002   45.930000  1739600.0   46.750000   46.490002   \n",
       "1       2017-01-04   46.820000   46.930000  1821300.0   47.380001   47.099998   \n",
       "2       2017-01-05   46.360001   47.049999  1503700.0   47.070000   46.540001   \n",
       "3       2017-01-06   46.560001   46.630001  2883400.0   48.070000   47.990002   \n",
       "4       2017-01-09   47.910000   48.009998  2575300.0   48.560001   48.139999   \n",
       "...            ...         ...         ...        ...         ...         ...   \n",
       "605210  2022-12-06  152.089996  154.220001  1964800.0  155.500000  153.050003   \n",
       "605211  2022-12-07  149.380005  152.960007  2444100.0  153.789993  150.250000   \n",
       "605212  2022-12-08  149.199997  150.529999  2267500.0  154.350006  153.679993   \n",
       "605213  2022-12-09  152.740005  153.940002  3274900.0  156.330002  153.389999   \n",
       "605214  2022-12-12  152.970001  154.070007   301135.0  154.470001  153.625000   \n",
       "\n",
       "        Adjusted Close Stock Name  \n",
       "0            44.433620          A  \n",
       "1            45.016628          A  \n",
       "2            44.481392          A  \n",
       "3            45.867260          A  \n",
       "4            46.010628          A  \n",
       "...                ...        ...  \n",
       "605210      153.050003        ZTS  \n",
       "605211      150.250000        ZTS  \n",
       "605212      153.679993        ZTS  \n",
       "605213      153.389999        ZTS  \n",
       "605214      153.625000        ZTS  \n",
       "\n",
       "[605215 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>industry</th>\n",
       "      <th>sector</th>\n",
       "      <th>country</th>\n",
       "      <th>beta</th>\n",
       "      <th>marketCap</th>\n",
       "      <th>bookValue</th>\n",
       "      <th>dividendRate</th>\n",
       "      <th>dividendYield</th>\n",
       "      <th>fiveYearAvgDividendYield</th>\n",
       "      <th>debtToEquity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.072</td>\n",
       "      <td>39891210240</td>\n",
       "      <td>20.530</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.66</td>\n",
       "      <td>52.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <td>Airlines</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.399</td>\n",
       "      <td>9680030720</td>\n",
       "      <td>-7.387</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>Specialty Retail</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.194</td>\n",
       "      <td>2744477440</td>\n",
       "      <td>42.340</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>2.44</td>\n",
       "      <td>171.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>Consumer Electronics</td>\n",
       "      <td>Technology</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.240</td>\n",
       "      <td>3622499778560</td>\n",
       "      <td>3.767</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.62</td>\n",
       "      <td>209.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>Drug Manufacturers - General</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.613</td>\n",
       "      <td>322113306624</td>\n",
       "      <td>3.413</td>\n",
       "      <td>6.56</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>4.13</td>\n",
       "      <td>1174.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XYL</th>\n",
       "      <td>Specialty Industrial Machinery</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.050</td>\n",
       "      <td>30846726144</td>\n",
       "      <td>43.593</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>1.16</td>\n",
       "      <td>19.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YUM</th>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.095</td>\n",
       "      <td>38885851136</td>\n",
       "      <td>-27.407</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBH</th>\n",
       "      <td>Medical Devices</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.021</td>\n",
       "      <td>21979760640</td>\n",
       "      <td>61.997</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.75</td>\n",
       "      <td>53.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZION</th>\n",
       "      <td>Banks - Regional</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.060</td>\n",
       "      <td>8874271744</td>\n",
       "      <td>40.251</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTS</th>\n",
       "      <td>Drug Manufacturers - Specialty &amp; Generic</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.896</td>\n",
       "      <td>80394125312</td>\n",
       "      <td>11.591</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.68</td>\n",
       "      <td>129.442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      industry              sector  \\\n",
       "A                       Diagnostics & Research          Healthcare   \n",
       "AAL                                   Airlines         Industrials   \n",
       "AAP                           Specialty Retail   Consumer Cyclical   \n",
       "AAPL                      Consumer Electronics          Technology   \n",
       "ABBV              Drug Manufacturers - General          Healthcare   \n",
       "...                                        ...                 ...   \n",
       "XYL             Specialty Industrial Machinery         Industrials   \n",
       "YUM                                Restaurants   Consumer Cyclical   \n",
       "ZBH                            Medical Devices          Healthcare   \n",
       "ZION                          Banks - Regional  Financial Services   \n",
       "ZTS   Drug Manufacturers - Specialty & Generic          Healthcare   \n",
       "\n",
       "            country   beta      marketCap  bookValue  dividendRate  \\\n",
       "A     United States  1.072    39891210240     20.530          0.99   \n",
       "AAL   United States  1.399     9680030720     -7.387          0.00   \n",
       "AAP   United States  1.194     2744477440     42.340          1.00   \n",
       "AAPL  United States  1.240  3622499778560      3.767          1.00   \n",
       "ABBV  United States  0.613   322113306624      3.413          6.56   \n",
       "...             ...    ...            ...        ...           ...   \n",
       "XYL   United States  1.050    30846726144     43.593          1.44   \n",
       "YUM   United States  1.095    38885851136    -27.407          2.68   \n",
       "ZBH   United States  1.021    21979760640     61.997          0.96   \n",
       "ZION  United States  1.060     8874271744     40.251          1.72   \n",
       "ZTS   United States  0.896    80394125312     11.591          1.73   \n",
       "\n",
       "      dividendYield  fiveYearAvgDividendYield  debtToEquity  \n",
       "A            0.0074                      0.66        52.787  \n",
       "AAL          0.0000                      1.27         0.000  \n",
       "AAP          0.0243                      2.44       171.801  \n",
       "AAPL         0.0042                      0.62       209.059  \n",
       "ABBV         0.0359                      4.13      1174.815  \n",
       "...             ...                       ...           ...  \n",
       "XYL          0.0114                      1.16        19.840  \n",
       "YUM          0.0193                      1.81         0.000  \n",
       "ZBH          0.0086                      0.75        53.611  \n",
       "ZION         0.0284                      3.47         0.000  \n",
       "ZTS          0.0099                      0.68       129.442  \n",
       "\n",
       "[408 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Software - Infrastructure', 'Technology', 'United States',\n",
       "       np.float64(0.904), np.int64(3204173004800), np.float64(38.693),\n",
       "       np.float64(3.32), np.float64(0.0078), np.float64(0.87),\n",
       "       np.float64(33.657)], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static.loc[\"MSFT\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tickers = static.index\n",
    "stock = stock[stock['Stock Name'].isin(valid_tickers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = stock.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_scaled_min_max, stock_scalar = scale_stock_data(stock, constant.columns_to_scale, 'min_max')\n",
    "stock_scaled_standard, stock_scalar = scale_stock_data(stock, constant.columns_to_scale, 'standard') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted Close</th>\n",
       "      <th>Stock Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>-1.435333</td>\n",
       "      <td>-1.441155</td>\n",
       "      <td>-0.219570</td>\n",
       "      <td>-1.429961</td>\n",
       "      <td>-1.425749</td>\n",
       "      <td>-1.417698</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>-1.403104</td>\n",
       "      <td>-1.411697</td>\n",
       "      <td>-0.141171</td>\n",
       "      <td>-1.411604</td>\n",
       "      <td>-1.407762</td>\n",
       "      <td>-1.400782</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>-1.416831</td>\n",
       "      <td>-1.408162</td>\n",
       "      <td>-0.445939</td>\n",
       "      <td>-1.420637</td>\n",
       "      <td>-1.424275</td>\n",
       "      <td>-1.416312</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>-1.410863</td>\n",
       "      <td>-1.420535</td>\n",
       "      <td>0.878017</td>\n",
       "      <td>-1.391499</td>\n",
       "      <td>-1.381520</td>\n",
       "      <td>-1.376100</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>-1.370577</td>\n",
       "      <td>-1.379882</td>\n",
       "      <td>0.582365</td>\n",
       "      <td>-1.377222</td>\n",
       "      <td>-1.377097</td>\n",
       "      <td>-1.371940</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605210</th>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>0.554631</td>\n",
       "      <td>0.564748</td>\n",
       "      <td>-0.238224</td>\n",
       "      <td>0.558351</td>\n",
       "      <td>0.541016</td>\n",
       "      <td>0.576112</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605211</th>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>0.498033</td>\n",
       "      <td>0.538759</td>\n",
       "      <td>0.239304</td>\n",
       "      <td>0.523447</td>\n",
       "      <td>0.483199</td>\n",
       "      <td>0.518625</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605212</th>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>0.494273</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.063357</td>\n",
       "      <td>0.534878</td>\n",
       "      <td>0.554024</td>\n",
       "      <td>0.589047</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605213</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>0.568207</td>\n",
       "      <td>0.558973</td>\n",
       "      <td>1.067032</td>\n",
       "      <td>0.575293</td>\n",
       "      <td>0.548036</td>\n",
       "      <td>0.583093</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605214</th>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>0.573010</td>\n",
       "      <td>0.561654</td>\n",
       "      <td>-1.895737</td>\n",
       "      <td>0.537327</td>\n",
       "      <td>0.552889</td>\n",
       "      <td>0.587917</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605215 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date       Low      Open    Volume      High     Close  \\\n",
       "0       2017-01-03 -1.435333 -1.441155 -0.219570 -1.429961 -1.425749   \n",
       "1       2017-01-04 -1.403104 -1.411697 -0.141171 -1.411604 -1.407762   \n",
       "2       2017-01-05 -1.416831 -1.408162 -0.445939 -1.420637 -1.424275   \n",
       "3       2017-01-06 -1.410863 -1.420535  0.878017 -1.391499 -1.381520   \n",
       "4       2017-01-09 -1.370577 -1.379882  0.582365 -1.377222 -1.377097   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "605210  2022-12-06  0.554631  0.564748 -0.238224  0.558351  0.541016   \n",
       "605211  2022-12-07  0.498033  0.538759  0.239304  0.523447  0.483199   \n",
       "605212  2022-12-08  0.494273  0.488636  0.063357  0.534878  0.554024   \n",
       "605213  2022-12-09  0.568207  0.558973  1.067032  0.575293  0.548036   \n",
       "605214  2022-12-12  0.573010  0.561654 -1.895737  0.537327  0.552889   \n",
       "\n",
       "        Adjusted Close Stock Name  \n",
       "0            -1.417698          A  \n",
       "1            -1.400782          A  \n",
       "2            -1.416312          A  \n",
       "3            -1.376100          A  \n",
       "4            -1.371940          A  \n",
       "...                ...        ...  \n",
       "605210        0.576112        ZTS  \n",
       "605211        0.518625        ZTS  \n",
       "605212        0.589047        ZTS  \n",
       "605213        0.583093        ZTS  \n",
       "605214        0.587917        ZTS  \n",
       "\n",
       "[605215 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_scaled_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted Close</th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Day of The Week</th>\n",
       "      <th>Week of The Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>0.113930</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>0.091776</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.188017</td>\n",
       "      <td>0.009938</td>\n",
       "      <td>0.011296</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016511</td>\n",
       "      <td>0.015598</td>\n",
       "      <td>0.166526</td>\n",
       "      <td>0.013627</td>\n",
       "      <td>0.012426</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605210</th>\n",
       "      <td>0.518709</td>\n",
       "      <td>0.522872</td>\n",
       "      <td>0.132240</td>\n",
       "      <td>0.522823</td>\n",
       "      <td>0.516862</td>\n",
       "      <td>0.526255</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605211</th>\n",
       "      <td>0.504664</td>\n",
       "      <td>0.516396</td>\n",
       "      <td>0.170338</td>\n",
       "      <td>0.514121</td>\n",
       "      <td>0.502468</td>\n",
       "      <td>0.511865</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605212</th>\n",
       "      <td>0.503731</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.156301</td>\n",
       "      <td>0.516971</td>\n",
       "      <td>0.520101</td>\n",
       "      <td>0.529492</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605213</th>\n",
       "      <td>0.522077</td>\n",
       "      <td>0.521433</td>\n",
       "      <td>0.236376</td>\n",
       "      <td>0.527047</td>\n",
       "      <td>0.518610</td>\n",
       "      <td>0.528002</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605214</th>\n",
       "      <td>0.523269</td>\n",
       "      <td>0.522101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517582</td>\n",
       "      <td>0.519818</td>\n",
       "      <td>0.529210</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605215 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Low      Open    Volume      High     Close  Adjusted Close  \\\n",
       "0       0.000000  0.000000  0.108231  0.000000  0.000000        0.000000   \n",
       "1       0.008217  0.007499  0.113930  0.004743  0.004594        0.004368   \n",
       "2       0.004717  0.008399  0.091776  0.002409  0.000377        0.000358   \n",
       "3       0.006239  0.005249  0.188017  0.009938  0.011296        0.010740   \n",
       "4       0.016511  0.015598  0.166526  0.013627  0.012426        0.011814   \n",
       "...          ...       ...       ...       ...       ...             ...   \n",
       "605210  0.518709  0.522872  0.132240  0.522823  0.516862        0.526255   \n",
       "605211  0.504664  0.516396  0.170338  0.514121  0.502468        0.511865   \n",
       "605212  0.503731  0.503906  0.156301  0.516971  0.520101        0.529492   \n",
       "605213  0.522077  0.521433  0.236376  0.527047  0.518610        0.528002   \n",
       "605214  0.523269  0.522101  0.000000  0.517582  0.519818        0.529210   \n",
       "\n",
       "       Stock Name  Month  Day  Day of The Week  Week of The Year  \n",
       "0               A      0    2                1                 0  \n",
       "1               A      0    3                2                 0  \n",
       "2               A      0    4                3                 0  \n",
       "3               A      0    5                4                 0  \n",
       "4               A      0    8                0                 1  \n",
       "...           ...    ...  ...              ...               ...  \n",
       "605210        ZTS     11    5                1                48  \n",
       "605211        ZTS     11    6                2                48  \n",
       "605212        ZTS     11    7                3                48  \n",
       "605213        ZTS     11    8                4                48  \n",
       "605214        ZTS     11   11                0                49  \n",
       "\n",
       "[605215 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = restructure_date_information(stock_scaled_min_max)\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = one_label_scale_static_df(static,constant.static_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cat_feature_num_list, history_cont_feature_num = get_feature_length(processed_df, constant.feature_variables)\n",
    "static_cat_feature_num_list , static_cont_feature_num  = get_feature_length(static, constant.static_variables)\n",
    "future_cat_feature_num_list , _                        = get_feature_length(processed_df, constant.future_feature)\n",
    "_                           , prediction_con           = get_feature_length(processed_df, constant.prediction_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([12, 31, 5, 53], 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_cat_feature_num_list, history_cont_feature_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_length = 90\n",
    "prediction_length = 15\n",
    "hidden_size = 128\n",
    "batch_size = 128\n",
    "dropout = .2\n",
    "num_head = 4\n",
    "lr= 0.0001\n",
    "momentum=0.9\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1\n",
    "split_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_Dataset = TFT_Dataset(tft_df= processed_df , \n",
    "                        static_df=static_df,\n",
    "                        autoformer_df = stock_scaled_standard,\n",
    "                        constant_variable=constant, \n",
    "                        history_length= history_length, \n",
    "                        tft_prediction_length= prediction_length, \n",
    "                        autoformer_prediction_length= 7 ,\n",
    "                        device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562375"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_Dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * fusion_Dataset.__len__())\n",
    "test_size = len(fusion_Dataset) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = random_split(fusion_Dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 7, 1]) cuda:0\n"
     ]
    }
   ],
   "source": [
    "count =0\n",
    "for static_cont_input, static_cat_input,history_cont_input, history_cat_input, future_input, prediction,autoformer_feature_input, autoformer_prediction in train_loader:\n",
    "    break\n",
    "print(autoformer_prediction.size(), autoformer_prediction.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFT(\n",
       "  (tft_embed): TFT_embedding(\n",
       "    (static_cont): Linear(in_features=7, out_features=128, bias=True)\n",
       "    (static_cat): ModuleList(\n",
       "      (0): Embedding(108, 128)\n",
       "      (1-2): 2 x Embedding(12, 128)\n",
       "    )\n",
       "    (history_cont): Linear(in_features=4, out_features=128, bias=True)\n",
       "    (history_cat): ModuleList(\n",
       "      (0): Embedding(12, 128)\n",
       "      (1): Embedding(31, 128)\n",
       "      (2): Embedding(5, 128)\n",
       "      (3): Embedding(53, 128)\n",
       "    )\n",
       "    (future_feature): ModuleList(\n",
       "      (0): Embedding(12, 128)\n",
       "      (1): Embedding(31, 128)\n",
       "      (2): Embedding(5, 128)\n",
       "      (3): Embedding(53, 128)\n",
       "    )\n",
       "  )\n",
       "  (cs): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-3): 4 x GRN(\n",
       "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ce): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-3): 4 x GRN(\n",
       "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cc): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-3): 4 x GRN(\n",
       "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ch): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-3): 4 x GRN(\n",
       "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (history_variation): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=640, out_features=640, bias=True)\n",
       "      (linear2): Linear(in_features=640, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=640, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=640, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=640, out_features=5, bias=True)\n",
       "      (linear_conext): Linear(in_features=128, out_features=640, bias=False)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-4): 5 x GRN(\n",
       "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (future_variation): VariationSelection(\n",
       "    (group_GRN): GRN(\n",
       "      (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "      (linear_conext): Linear(in_features=128, out_features=512, bias=False)\n",
       "    )\n",
       "    (individual_GRN): ModuleList(\n",
       "      (0-3): 4 x GRN(\n",
       "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (gate_add_norm_history): Gate_Add_Norm(\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (gate_add_norm_future): Gate_Add_Norm(\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (GRN): GRN(\n",
       "    (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (droput): Dropout(p=0.0, inplace=False)\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (linear_conext): Linear(in_features=128, out_features=128, bias=False)\n",
       "  )\n",
       "  (history_lstm): LSTM(128, 128, batch_first=True)\n",
       "  (future_lstm): LSTM(128, 128, batch_first=True)\n",
       "  (history_layernorm): LayerNorm((128,), eps=0.2, elementwise_affine=True)\n",
       "  (future_layernorm): LayerNorm((128,), eps=0.2, elementwise_affine=True)\n",
       "  (InterpAttention): InterpretableMultiHeadAttention(\n",
       "    (q_linear): ModuleList(\n",
       "      (0-3): 4 x Linear(in_features=128, out_features=32, bias=True)\n",
       "    )\n",
       "    (k_linear): ModuleList(\n",
       "      (0-3): 4 x Linear(in_features=128, out_features=32, bias=True)\n",
       "    )\n",
       "    (v_linear): Linear(in_features=128, out_features=105, bias=True)\n",
       "  )\n",
       "  (attention_layernorm): LayerNorm((105,), eps=0.2, elementwise_affine=True)\n",
       "  (gate_add_norm_attention): Gate_Add_Norm(\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=105, out_features=128, bias=True)\n",
       "      (linear5): Linear(in_features=105, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (attention_GRN): GRN(\n",
       "    (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (droput): Dropout(p=0.0, inplace=False)\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (gate_add_norm_last): Gate_Add_Norm(\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=15, out_features=128, bias=True)\n",
       "      (linear5): Linear(in_features=15, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (GLU): GLU(\n",
       "    (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (output_linear): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tft_model = TFT(static_cat_feature_num_list= static_cat_feature_num_list,\n",
    "            static_cont_feature_num=static_cont_feature_num,\n",
    "            history_cat_feature_num_list= history_cat_feature_num_list,\n",
    "            history_cont_feature_num=history_cont_feature_num,\n",
    "            future_cat_feature_num_list=future_cat_feature_num_list,\n",
    "            history_len = history_length,\n",
    "            future_len = prediction_length,\n",
    "            dropout= dropout,\n",
    "            num_head = num_head,\n",
    "            hidden_size = hidden_size,\n",
    "            device = device)\n",
    "\n",
    "tft_model.load_state_dict(torch.load(f'tft_model_{year}.pth', weights_only=True))\n",
    "tft_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luan\\AppData\\Local\\Temp\\ipykernel_21700\\201841490.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  autoformer_model.load_state_dict(torch.load('best_long.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Autoformer(\n",
       "  (input_projection): Linear(in_features=5, out_features=128, bias=True)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (decomposition): DecompositionLayer(\n",
       "    (moving_avg): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.01, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x DecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (cross_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.01, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_projection): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoformer_model = Autoformer(**constant.autoformer_model_config)\n",
    "autoformer_model.load_state_dict(torch.load('best_long.pth'))\n",
    "autoformer_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model_Fusion(\n",
       "  (tft_model): TFT(\n",
       "    (tft_embed): TFT_embedding(\n",
       "      (static_cont): Linear(in_features=7, out_features=128, bias=True)\n",
       "      (static_cat): ModuleList(\n",
       "        (0): Embedding(108, 128)\n",
       "        (1-2): 2 x Embedding(12, 128)\n",
       "      )\n",
       "      (history_cont): Linear(in_features=4, out_features=128, bias=True)\n",
       "      (history_cat): ModuleList(\n",
       "        (0): Embedding(12, 128)\n",
       "        (1): Embedding(31, 128)\n",
       "        (2): Embedding(5, 128)\n",
       "        (3): Embedding(53, 128)\n",
       "      )\n",
       "      (future_feature): ModuleList(\n",
       "        (0): Embedding(12, 128)\n",
       "        (1): Embedding(31, 128)\n",
       "        (2): Embedding(5, 128)\n",
       "        (3): Embedding(53, 128)\n",
       "      )\n",
       "    )\n",
       "    (cs): VariationSelection(\n",
       "      (group_GRN): GRN(\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "      )\n",
       "      (individual_GRN): ModuleList(\n",
       "        (0-3): 4 x GRN(\n",
       "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (GLU): GLU(\n",
       "            (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (droput): Dropout(p=0.0, inplace=False)\n",
       "          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ce): VariationSelection(\n",
       "      (group_GRN): GRN(\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "      )\n",
       "      (individual_GRN): ModuleList(\n",
       "        (0-3): 4 x GRN(\n",
       "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (GLU): GLU(\n",
       "            (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (droput): Dropout(p=0.0, inplace=False)\n",
       "          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cc): VariationSelection(\n",
       "      (group_GRN): GRN(\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "      )\n",
       "      (individual_GRN): ModuleList(\n",
       "        (0-3): 4 x GRN(\n",
       "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (GLU): GLU(\n",
       "            (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (droput): Dropout(p=0.0, inplace=False)\n",
       "          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ch): VariationSelection(\n",
       "      (group_GRN): GRN(\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "      )\n",
       "      (individual_GRN): ModuleList(\n",
       "        (0-3): 4 x GRN(\n",
       "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (GLU): GLU(\n",
       "            (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (droput): Dropout(p=0.0, inplace=False)\n",
       "          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (history_variation): VariationSelection(\n",
       "      (group_GRN): GRN(\n",
       "        (linear1): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (linear2): Linear(in_features=640, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=640, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=640, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_out): Linear(in_features=640, out_features=5, bias=True)\n",
       "        (linear_conext): Linear(in_features=128, out_features=640, bias=False)\n",
       "      )\n",
       "      (individual_GRN): ModuleList(\n",
       "        (0-4): 5 x GRN(\n",
       "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (GLU): GLU(\n",
       "            (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (droput): Dropout(p=0.0, inplace=False)\n",
       "          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (future_variation): VariationSelection(\n",
       "      (group_GRN): GRN(\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "        (linear_conext): Linear(in_features=128, out_features=512, bias=False)\n",
       "      )\n",
       "      (individual_GRN): ModuleList(\n",
       "        (0-3): 4 x GRN(\n",
       "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (GLU): GLU(\n",
       "            (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (droput): Dropout(p=0.0, inplace=False)\n",
       "          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (gate_add_norm_history): Gate_Add_Norm(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gate_add_norm_future): Gate_Add_Norm(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (GRN): GRN(\n",
       "      (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_conext): Linear(in_features=128, out_features=128, bias=False)\n",
       "    )\n",
       "    (history_lstm): LSTM(128, 128, batch_first=True)\n",
       "    (future_lstm): LSTM(128, 128, batch_first=True)\n",
       "    (history_layernorm): LayerNorm((128,), eps=0.2, elementwise_affine=True)\n",
       "    (future_layernorm): LayerNorm((128,), eps=0.2, elementwise_affine=True)\n",
       "    (InterpAttention): InterpretableMultiHeadAttention(\n",
       "      (q_linear): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=32, bias=True)\n",
       "      )\n",
       "      (k_linear): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=32, bias=True)\n",
       "      )\n",
       "      (v_linear): Linear(in_features=128, out_features=105, bias=True)\n",
       "    )\n",
       "    (attention_layernorm): LayerNorm((105,), eps=0.2, elementwise_affine=True)\n",
       "    (gate_add_norm_attention): Gate_Add_Norm(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=105, out_features=128, bias=True)\n",
       "        (linear5): Linear(in_features=105, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (attention_GRN): GRN(\n",
       "      (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (gate_add_norm_last): Gate_Add_Norm(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=15, out_features=128, bias=True)\n",
       "        (linear5): Linear(in_features=15, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (output_linear): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       "  (autoformer_model): Autoformer(\n",
       "    (input_projection): Linear(in_features=5, out_features=128, bias=True)\n",
       "    (positional_encoding): PositionalEncoding()\n",
       "    (decomposition): DecompositionLayer(\n",
       "      (moving_avg): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    )\n",
       "    (encoder): Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x EncoderLayer(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (ffn): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x DecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (cross_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (ffn): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_projection): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (attentionfusion): AttentionFusion(\n",
       "    (cross_list): ModuleList(\n",
       "      (0): CrossAttention(\n",
       "        (q_linear): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (k_linear): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (v_linear): Linear(in_features=128, out_features=15, bias=True)\n",
       "        (attention_output_linear): Linear(in_features=15, out_features=128, bias=True)\n",
       "        (q_residual): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (glu): GLU(\n",
       "    (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (linear_output): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion = Model_Fusion(tft_model=tft_model , \n",
    "             autoformer_model = autoformer_model,\n",
    "             n_head= 1,\n",
    "             hidden_size=hidden_size,\n",
    "             device=device)\n",
    "fusion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = QuantilesLoss( device=device)\n",
    "loss_function.to(device)\n",
    "optimizer = optim.Adam(fusion.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 0,  Loss: 0.5517359972000122\n",
      "Epoch: 1, Batch: 1000,  Loss: 0.03219452127814293\n",
      "Epoch: 1, Batch: 2000,  Loss: 0.025751158595085144\n",
      "Epoch: 1, Batch: 3000,  Loss: 0.025091728195548058\n",
      "###########################\n",
      "Epoch: 1,  Loss: 0.03178217634558678\n",
      "Epoch: 2, Batch: 0,  Loss: 0.02982131764292717\n",
      "Epoch: 2, Batch: 1000,  Loss: 0.0267740860581398\n",
      "Epoch: 2, Batch: 2000,  Loss: 0.021991848945617676\n",
      "Epoch: 2, Batch: 3000,  Loss: 0.02645004540681839\n",
      "###########################\n",
      "Epoch: 2,  Loss: 0.021673955023288727\n",
      "Epoch: 3, Batch: 0,  Loss: 0.023682726547122\n",
      "Epoch: 3, Batch: 1000,  Loss: 0.02163458801805973\n",
      "Epoch: 3, Batch: 2000,  Loss: 0.021390549838542938\n",
      "Epoch: 3, Batch: 3000,  Loss: 0.022306276485323906\n",
      "###########################\n",
      "Epoch: 3,  Loss: 0.019116155803203583\n",
      "Epoch: 4, Batch: 0,  Loss: 0.022741403430700302\n",
      "Epoch: 4, Batch: 1000,  Loss: 0.018931131809949875\n",
      "Epoch: 4, Batch: 2000,  Loss: 0.0212588831782341\n",
      "Epoch: 4, Batch: 3000,  Loss: 0.018070384860038757\n",
      "###########################\n",
      "Epoch: 4,  Loss: 0.019489675760269165\n",
      "Epoch: 5, Batch: 0,  Loss: 0.020359531044960022\n",
      "Epoch: 5, Batch: 1000,  Loss: 0.022953886538743973\n",
      "Epoch: 5, Batch: 2000,  Loss: 0.019239656627178192\n",
      "Epoch: 5, Batch: 3000,  Loss: 0.017977040261030197\n",
      "###########################\n",
      "Epoch: 5,  Loss: 0.019835669547319412\n",
      "Epoch: 6, Batch: 0,  Loss: 0.020184699445962906\n",
      "Epoch: 6, Batch: 1000,  Loss: 0.01884753629565239\n",
      "Epoch: 6, Batch: 2000,  Loss: 0.018889879807829857\n",
      "Epoch: 6, Batch: 3000,  Loss: 0.018174342811107635\n",
      "###########################\n",
      "Epoch: 6,  Loss: 0.017008207738399506\n",
      "Epoch: 7, Batch: 0,  Loss: 0.018762843683362007\n",
      "Epoch: 7, Batch: 1000,  Loss: 0.018796339631080627\n",
      "Epoch: 7, Batch: 2000,  Loss: 0.017629120498895645\n",
      "Epoch: 7, Batch: 3000,  Loss: 0.016799412667751312\n",
      "###########################\n",
      "Epoch: 7,  Loss: 0.016389548778533936\n",
      "Epoch: 8, Batch: 0,  Loss: 0.016801999881863594\n",
      "Epoch: 8, Batch: 1000,  Loss: 0.017029792070388794\n",
      "Epoch: 8, Batch: 2000,  Loss: 0.017245793715119362\n",
      "Epoch: 8, Batch: 3000,  Loss: 0.017247969284653664\n",
      "###########################\n",
      "Epoch: 8,  Loss: 0.019381430000066757\n",
      "Epoch: 9, Batch: 0,  Loss: 0.015884844586253166\n",
      "Epoch: 9, Batch: 1000,  Loss: 0.015220483765006065\n",
      "Epoch: 9, Batch: 2000,  Loss: 0.017302215099334717\n",
      "Epoch: 9, Batch: 3000,  Loss: 0.01669915020465851\n",
      "###########################\n",
      "Epoch: 9,  Loss: 0.017883699387311935\n",
      "Epoch: 10, Batch: 0,  Loss: 0.015125535428524017\n",
      "Epoch: 10, Batch: 1000,  Loss: 0.01777244731783867\n",
      "Epoch: 10, Batch: 2000,  Loss: 0.016866350546479225\n",
      "Epoch: 10, Batch: 3000,  Loss: 0.018658913671970367\n",
      "###########################\n",
      "Epoch: 10,  Loss: 0.01683798059821129\n"
     ]
    }
   ],
   "source": [
    "fusion.train()\n",
    "batch_loss = [] \n",
    "for epoch in range(num_epochs):\n",
    "    for i,(static_cont_input, static_cat_input,history_cont_input, history_cat_input,future_input, tft_prediction, autoformer_feature_input, autoformer_prediction) in enumerate(train_loader):\n",
    "        output = fusion( static_cont_input, static_cat_input,history_cont_input, history_cat_input,future_input, tft_prediction, autoformer_feature_input, autoformer_prediction)\n",
    "        optimizer.zero_grad()\n",
    "        losses = loss_function(predicted = output, targets = tft_prediction)\n",
    "        loss = losses.sum()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(f'Epoch: {epoch+1}, Batch: {i},  Loss: {loss.item()}')\n",
    "        batch_loss.append(loss.item())\n",
    "    print(\"###########################\")\n",
    "    print(f'Epoch: {epoch+1},  Loss: {loss.item()}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 15, 128])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(fusion.state_dict(), f\"fusion_model_{year}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model_Fusion(\n",
       "  (tft_model): TFT(\n",
       "    (tft_embed): TFT_embedding(\n",
       "      (static_cont): Linear(in_features=7, out_features=128, bias=True)\n",
       "      (static_cat): ModuleList(\n",
       "        (0): Embedding(108, 128)\n",
       "        (1-2): 2 x Embedding(12, 128)\n",
       "      )\n",
       "      (history_cont): Linear(in_features=4, out_features=128, bias=True)\n",
       "      (history_cat): ModuleList(\n",
       "        (0): Embedding(12, 128)\n",
       "        (1): Embedding(31, 128)\n",
       "        (2): Embedding(5, 128)\n",
       "        (3): Embedding(53, 128)\n",
       "      )\n",
       "      (future_feature): ModuleList(\n",
       "        (0): Embedding(12, 128)\n",
       "        (1): Embedding(31, 128)\n",
       "        (2): Embedding(5, 128)\n",
       "        (3): Embedding(53, 128)\n",
       "      )\n",
       "    )\n",
       "    (cs): VariationSelection(\n",
       "      (group_GRN): GRN(\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "      )\n",
       "      (individual_GRN): ModuleList(\n",
       "        (0-3): 4 x GRN(\n",
       "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (GLU): GLU(\n",
       "            (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (droput): Dropout(p=0.0, inplace=False)\n",
       "          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ce): VariationSelection(\n",
       "      (group_GRN): GRN(\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "      )\n",
       "      (individual_GRN): ModuleList(\n",
       "        (0-3): 4 x GRN(\n",
       "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (GLU): GLU(\n",
       "            (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (droput): Dropout(p=0.0, inplace=False)\n",
       "          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cc): VariationSelection(\n",
       "      (group_GRN): GRN(\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "      )\n",
       "      (individual_GRN): ModuleList(\n",
       "        (0-3): 4 x GRN(\n",
       "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (GLU): GLU(\n",
       "            (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (droput): Dropout(p=0.0, inplace=False)\n",
       "          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ch): VariationSelection(\n",
       "      (group_GRN): GRN(\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "      )\n",
       "      (individual_GRN): ModuleList(\n",
       "        (0-3): 4 x GRN(\n",
       "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (GLU): GLU(\n",
       "            (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (droput): Dropout(p=0.0, inplace=False)\n",
       "          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (history_variation): VariationSelection(\n",
       "      (group_GRN): GRN(\n",
       "        (linear1): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (linear2): Linear(in_features=640, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=640, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=640, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_out): Linear(in_features=640, out_features=5, bias=True)\n",
       "        (linear_conext): Linear(in_features=128, out_features=640, bias=False)\n",
       "      )\n",
       "      (individual_GRN): ModuleList(\n",
       "        (0-4): 5 x GRN(\n",
       "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (GLU): GLU(\n",
       "            (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (droput): Dropout(p=0.0, inplace=False)\n",
       "          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (future_variation): VariationSelection(\n",
       "      (group_GRN): GRN(\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (GLU): GLU(\n",
       "          (linear4): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (linear5): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (droput): Dropout(p=0.0, inplace=False)\n",
       "        (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_out): Linear(in_features=512, out_features=4, bias=True)\n",
       "        (linear_conext): Linear(in_features=128, out_features=512, bias=False)\n",
       "      )\n",
       "      (individual_GRN): ModuleList(\n",
       "        (0-3): 4 x GRN(\n",
       "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (GLU): GLU(\n",
       "            (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (droput): Dropout(p=0.0, inplace=False)\n",
       "          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (gate_add_norm_history): Gate_Add_Norm(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gate_add_norm_future): Gate_Add_Norm(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (GRN): GRN(\n",
       "      (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_conext): Linear(in_features=128, out_features=128, bias=False)\n",
       "    )\n",
       "    (history_lstm): LSTM(128, 128, batch_first=True)\n",
       "    (future_lstm): LSTM(128, 128, batch_first=True)\n",
       "    (history_layernorm): LayerNorm((128,), eps=0.2, elementwise_affine=True)\n",
       "    (future_layernorm): LayerNorm((128,), eps=0.2, elementwise_affine=True)\n",
       "    (InterpAttention): InterpretableMultiHeadAttention(\n",
       "      (q_linear): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=32, bias=True)\n",
       "      )\n",
       "      (k_linear): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=32, bias=True)\n",
       "      )\n",
       "      (v_linear): Linear(in_features=128, out_features=105, bias=True)\n",
       "    )\n",
       "    (attention_layernorm): LayerNorm((105,), eps=0.2, elementwise_affine=True)\n",
       "    (gate_add_norm_attention): Gate_Add_Norm(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=105, out_features=128, bias=True)\n",
       "        (linear5): Linear(in_features=105, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (attention_GRN): GRN(\n",
       "      (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (droput): Dropout(p=0.0, inplace=False)\n",
       "      (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (gate_add_norm_last): Gate_Add_Norm(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (GLU): GLU(\n",
       "        (linear4): Linear(in_features=15, out_features=128, bias=True)\n",
       "        (linear5): Linear(in_features=15, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (GLU): GLU(\n",
       "      (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (output_linear): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       "  (autoformer_model): Autoformer(\n",
       "    (input_projection): Linear(in_features=5, out_features=128, bias=True)\n",
       "    (positional_encoding): PositionalEncoding()\n",
       "    (decomposition): DecompositionLayer(\n",
       "      (moving_avg): AvgPool1d(kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    )\n",
       "    (encoder): Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x EncoderLayer(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (ffn): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x DecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (cross_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (ffn): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.01, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_projection): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (attentionfusion): AttentionFusion(\n",
       "    (cross_list): ModuleList(\n",
       "      (0): CrossAttention(\n",
       "        (q_linear): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (k_linear): ModuleList(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (v_linear): Linear(in_features=128, out_features=15, bias=True)\n",
       "        (attention_output_linear): Linear(in_features=15, out_features=128, bias=True)\n",
       "        (q_residual): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (glu): GLU(\n",
       "    (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (linear5): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (linear_output): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion = Model_Fusion(tft_model=tft_model , \n",
    "             autoformer_model = autoformer_model,\n",
    "             n_head= 1,\n",
    "             hidden_size=hidden_size,\n",
    "             device=device)\n",
    "fusion.load_state_dict(torch.load(f\"fusion_model_{year}.pth\", weights_only=True))\n",
    "fusion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion.eval()\n",
    "count = 0\n",
    "err = 0\n",
    "with torch.no_grad():\n",
    "    for i,(static_cont_input, static_cat_input,history_cont_input, history_cat_input,future_input, tft_prediction, autoformer_feature_input, autoformer_prediction) in enumerate(test_loader):\n",
    "        output = fusion( static_cont_input, static_cat_input,history_cont_input, history_cat_input,future_input, tft_prediction, autoformer_feature_input, autoformer_prediction)\n",
    "\n",
    "        diff = (tft_prediction.squeeze(-1) - output[:,:,1])**2\n",
    "        err += diff.sum()\n",
    "        count += diff.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Test Data:  0.010987406596541405\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE of Test Data: \", (err/count).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Stock Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-11 00:00:00-05:00</td>\n",
       "      <td>368.480011</td>\n",
       "      <td>371.600006</td>\n",
       "      <td>366.100006</td>\n",
       "      <td>371.299988</td>\n",
       "      <td>368.544067</td>\n",
       "      <td>27708800</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-12 00:00:00-05:00</td>\n",
       "      <td>370.850006</td>\n",
       "      <td>374.420013</td>\n",
       "      <td>370.459991</td>\n",
       "      <td>374.380005</td>\n",
       "      <td>371.601166</td>\n",
       "      <td>24838300</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-13 00:00:00-05:00</td>\n",
       "      <td>376.019989</td>\n",
       "      <td>377.640015</td>\n",
       "      <td>370.769989</td>\n",
       "      <td>374.369995</td>\n",
       "      <td>371.591278</td>\n",
       "      <td>30955500</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-14 00:00:00-05:00</td>\n",
       "      <td>373.309998</td>\n",
       "      <td>373.760010</td>\n",
       "      <td>364.130005</td>\n",
       "      <td>365.929993</td>\n",
       "      <td>363.213928</td>\n",
       "      <td>43277500</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-15 00:00:00-05:00</td>\n",
       "      <td>366.850006</td>\n",
       "      <td>372.399994</td>\n",
       "      <td>366.279999</td>\n",
       "      <td>370.730011</td>\n",
       "      <td>367.978302</td>\n",
       "      <td>78478200</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2024-12-04 00:00:00-05:00</td>\n",
       "      <td>433.029999</td>\n",
       "      <td>439.670013</td>\n",
       "      <td>432.630005</td>\n",
       "      <td>437.420013</td>\n",
       "      <td>437.420013</td>\n",
       "      <td>26009400</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2024-12-05 00:00:00-05:00</td>\n",
       "      <td>437.920013</td>\n",
       "      <td>444.660004</td>\n",
       "      <td>436.170013</td>\n",
       "      <td>442.619995</td>\n",
       "      <td>442.619995</td>\n",
       "      <td>21697800</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2024-12-06 00:00:00-05:00</td>\n",
       "      <td>442.299988</td>\n",
       "      <td>446.100006</td>\n",
       "      <td>441.769989</td>\n",
       "      <td>443.570007</td>\n",
       "      <td>443.570007</td>\n",
       "      <td>18821000</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2024-12-09 00:00:00-05:00</td>\n",
       "      <td>442.600006</td>\n",
       "      <td>448.329987</td>\n",
       "      <td>440.500000</td>\n",
       "      <td>446.019989</td>\n",
       "      <td>446.019989</td>\n",
       "      <td>19144400</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2024-12-10 00:00:00-05:00</td>\n",
       "      <td>444.390015</td>\n",
       "      <td>449.619995</td>\n",
       "      <td>441.600006</td>\n",
       "      <td>443.329987</td>\n",
       "      <td>443.329987</td>\n",
       "      <td>18453100</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Date        Open        High         Low       Close  \\\n",
       "0   2023-12-11 00:00:00-05:00  368.480011  371.600006  366.100006  371.299988   \n",
       "1   2023-12-12 00:00:00-05:00  370.850006  374.420013  370.459991  374.380005   \n",
       "2   2023-12-13 00:00:00-05:00  376.019989  377.640015  370.769989  374.369995   \n",
       "3   2023-12-14 00:00:00-05:00  373.309998  373.760010  364.130005  365.929993   \n",
       "4   2023-12-15 00:00:00-05:00  366.850006  372.399994  366.279999  370.730011   \n",
       "..                        ...         ...         ...         ...         ...   \n",
       "247 2024-12-04 00:00:00-05:00  433.029999  439.670013  432.630005  437.420013   \n",
       "248 2024-12-05 00:00:00-05:00  437.920013  444.660004  436.170013  442.619995   \n",
       "249 2024-12-06 00:00:00-05:00  442.299988  446.100006  441.769989  443.570007   \n",
       "250 2024-12-09 00:00:00-05:00  442.600006  448.329987  440.500000  446.019989   \n",
       "251 2024-12-10 00:00:00-05:00  444.390015  449.619995  441.600006  443.329987   \n",
       "\n",
       "     Adjusted Close    Volume Stock Name  \n",
       "0        368.544067  27708800       MSFT  \n",
       "1        371.601166  24838300       MSFT  \n",
       "2        371.591278  30955500       MSFT  \n",
       "3        363.213928  43277500       MSFT  \n",
       "4        367.978302  78478200       MSFT  \n",
       "..              ...       ...        ...  \n",
       "247      437.420013  26009400       MSFT  \n",
       "248      442.619995  21697800       MSFT  \n",
       "249      443.570007  18821000       MSFT  \n",
       "250      446.019989  19144400       MSFT  \n",
       "251      443.329987  18453100       MSFT  \n",
       "\n",
       "[252 rows x 8 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft = yf.Ticker(\"MSFT\")\n",
    "msft = msft.history(interval=\"1d\", period = \"1y\", auto_adjust=False, actions=False)\n",
    "msft.rename(columns={'Adj Close': 'Adjusted Close'}, inplace=True)\n",
    "msft[\"Stock Name\"] = \"MSFT\"\n",
    "msft = msft.reset_index()\n",
    "msft['Date'] = pd.to_datetime(msft['Date'])\n",
    "msft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_min_max, stock_scalar = scale_stock_data(msft, constant.columns_to_scale, 'min_max')\n",
    "msft_scaled_standard, stock_scalar = scale_stock_data(msft, constant.columns_to_scale, 'standard') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Day of The Week</th>\n",
       "      <th>Week of The Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019635</td>\n",
       "      <td>0.052839</td>\n",
       "      <td>0.051965</td>\n",
       "      <td>0.259332</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039940</td>\n",
       "      <td>0.029147</td>\n",
       "      <td>0.063092</td>\n",
       "      <td>0.083145</td>\n",
       "      <td>0.081769</td>\n",
       "      <td>0.217454</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.091562</td>\n",
       "      <td>0.062429</td>\n",
       "      <td>0.066181</td>\n",
       "      <td>0.083046</td>\n",
       "      <td>0.081672</td>\n",
       "      <td>0.306697</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064503</td>\n",
       "      <td>0.022326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.486462</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008269</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.047230</td>\n",
       "      <td>0.046449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.660809</td>\n",
       "      <td>0.703566</td>\n",
       "      <td>0.682747</td>\n",
       "      <td>0.703434</td>\n",
       "      <td>0.723450</td>\n",
       "      <td>0.234539</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.709636</td>\n",
       "      <td>0.755142</td>\n",
       "      <td>0.718031</td>\n",
       "      <td>0.754600</td>\n",
       "      <td>0.774146</td>\n",
       "      <td>0.171638</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.753370</td>\n",
       "      <td>0.770026</td>\n",
       "      <td>0.773846</td>\n",
       "      <td>0.763948</td>\n",
       "      <td>0.783408</td>\n",
       "      <td>0.129669</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.756365</td>\n",
       "      <td>0.793075</td>\n",
       "      <td>0.761188</td>\n",
       "      <td>0.788055</td>\n",
       "      <td>0.807293</td>\n",
       "      <td>0.134387</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.774239</td>\n",
       "      <td>0.806408</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.761586</td>\n",
       "      <td>0.781068</td>\n",
       "      <td>0.124302</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open      High       Low     Close  Adjusted Close    Volume  \\\n",
       "0    0.016276  0.000000  0.019635  0.052839        0.051965  0.259332   \n",
       "1    0.039940  0.029147  0.063092  0.083145        0.081769  0.217454   \n",
       "2    0.091562  0.062429  0.066181  0.083046        0.081672  0.306697   \n",
       "3    0.064503  0.022326  0.000000  0.000000        0.000000  0.486462   \n",
       "4    0.000000  0.008269  0.021429  0.047230        0.046449  1.000000   \n",
       "..        ...       ...       ...       ...             ...       ...   \n",
       "247  0.660809  0.703566  0.682747  0.703434        0.723450  0.234539   \n",
       "248  0.709636  0.755142  0.718031  0.754600        0.774146  0.171638   \n",
       "249  0.753370  0.770026  0.773846  0.763948        0.783408  0.129669   \n",
       "250  0.756365  0.793075  0.761188  0.788055        0.807293  0.134387   \n",
       "251  0.774239  0.806408  0.772152  0.761586        0.781068  0.124302   \n",
       "\n",
       "    Stock Name  Month  Day  Day of The Week  Week of The Year  \n",
       "0         MSFT     11   10                0                49  \n",
       "1         MSFT     11   11                1                49  \n",
       "2         MSFT     11   12                2                49  \n",
       "3         MSFT     11   13                3                49  \n",
       "4         MSFT     11   14                4                49  \n",
       "..         ...    ...  ...              ...               ...  \n",
       "247       MSFT     11    3                2                48  \n",
       "248       MSFT     11    4                3                48  \n",
       "249       MSFT     11    5                4                48  \n",
       "250       MSFT     11    8                0                49  \n",
       "251       MSFT     11    9                1                49  \n",
       "\n",
       "[252 rows x 11 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_df = restructure_date_information(msft_min_max)\n",
    "msft_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_Dataset = TFT_Dataset(tft_df= msft_df , \n",
    "                        static_df=static_df,\n",
    "                        autoformer_df = msft_scaled_standard,\n",
    "                        constant_variable=constant, \n",
    "                        history_length= history_length, \n",
    "                        tft_prediction_length= prediction_length, \n",
    "                        autoformer_prediction_length= 7 ,\n",
    "                        device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(msft_Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_loader = DataLoader(msft_Dataset , batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion.eval()\n",
    "count = 0\n",
    "fusion_err = 0\n",
    "tft_err = 0 \n",
    "autoformer_err = 0\n",
    "with torch.no_grad():\n",
    "    for i,(static_cont_input, static_cat_input,history_cont_input, history_cat_input,future_input, tft_prediction, autoformer_feature_input, autoformer_prediction) in enumerate(msft_loader):\n",
    "        output = fusion( static_cont_input, static_cat_input,history_cont_input, history_cat_input,future_input, tft_prediction, autoformer_feature_input, autoformer_prediction)\n",
    "        tft_output = tft_model(static_cont_input, static_cat_input,history_cont_input, history_cat_input, future_input)\n",
    "        autoformer_output = autoformer_model(autoformer_feature_input, autoformer_prediction)\n",
    "        \n",
    "        diff = (tft_prediction.squeeze(-1) - output[:,:,1])**2\n",
    "        fusion_err += diff.sum()\n",
    "\n",
    "        diff = (tft_prediction.squeeze(-1) - tft_output[:,:,1])**2\n",
    "        tft_err += diff.sum()\n",
    "        \n",
    "        diff = (tft_prediction.squeeze(-1)[:,:7] - autoformer_output)**2\n",
    "        autoformer_err += diff.sum()\n",
    "\n",
    "        count += diff.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Fusion on Novel Data: 0.1820930689573288\n",
      "MSE of TFT on Novel Data: 0.6633161306381226\n",
      "MSE of Autoformer on Novel Data: 67.6326904296875\n"
     ]
    }
   ],
   "source": [
    "print('MSE of Fusion on Novel Data:' , (fusion_err/count).item())\n",
    "print('MSE of TFT on Novel Data:' , (tft_err/count).item())\n",
    "print('MSE of Autoformer on Novel Data:' , (autoformer_err/count).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
